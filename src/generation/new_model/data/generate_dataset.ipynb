{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sections_dataset(dial_filepath, doc_filepath):\n",
    "    \"question_id | question_txt | domain | answer_id | answer_txt | span_id | span_txt | section_id | section_txt | document_id | document_txt \"\n",
    "    sections_dataset = []\n",
    "\n",
    "    with open(dial_filepath, 'r') as f:\n",
    "        questions_dataset = json.load(f)['dial_data']\n",
    "\n",
    "    with open(doc_filepath, 'r') as f:\n",
    "        doc_dataset = json.load(f)['doc_data']\n",
    "    \n",
    "    for domain, domain_dials in questions_dataset.items():\n",
    "        for dial in tqdm(domain_dials):\n",
    "            for i, turn in enumerate(dial['turns'][:-1]):\n",
    "                if turn['role'] == 'user':\n",
    "                    if dial['turns'][i+1]['role'] == 'agent':\n",
    "                        agent_turn = dial['turns'][i+1]\n",
    "                        question = dial['turns'][i]['utterance']\n",
    "                        answer = dial['turns'][i+1]['utterance']\n",
    "                        if len(agent_turn['references']):\n",
    "                            doc_id = agent_turn['references'][0]['doc_id']\n",
    "                            doc_text = doc_dataset[domain][doc_id]['doc_text']\n",
    "                            spans_text = \"\"\n",
    "                            for ref in agent_turn['references']:\n",
    "                                span_id = ref['id_sp']\n",
    "                                spans_text += doc_dataset[domain][doc_id]['spans'][span_id]['text_sp'] + \" \"\n",
    "                                section_text = doc_dataset[domain][doc_id]['spans'][span_id]['text_sec']\n",
    "                        else:\n",
    "                            print(f\"{dial['dial_id']}_{i}\".center(50, '='))\n",
    "                        sections_dataset.append({\n",
    "                            'question_id': f\"{dial['dial_id']}_{i+1}\",\n",
    "                            'question_text': question,\n",
    "                            'domain': domain,\n",
    "                            'answer_id': f\"{dial['dial_id']}_{i+2}\",\n",
    "                            'utterance': answer,\n",
    "                            'grounding': spans_text,\n",
    "                            'section_text': section_text, \n",
    "                            'document_id': doc_id,\n",
    "                            'document_text': doc_text, \n",
    "                        })\n",
    "                    else:\n",
    "                        continue\n",
    "    return sections_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = construct_sections_dataset('multidoc2dial/multidoc2dial_dial_train.json', 'multidoc2dial/multidoc2dial_doc.json')\n",
    "val = construct_sections_dataset('multidoc2dial/multidoc2dial_dial_validation.json', 'multidoc2dial/multidoc2dial_doc.json')\n",
    "test = construct_sections_dataset('multidoc2dial/multidoc2dial_dial_test.json', 'multidoc2dial/multidoc2dial_doc.json')\n",
    "df_train = pd.DataFrame(train)\n",
    "df_val = pd.DataFrame(val)\n",
    "df_test = pd.DataFrame(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('dataset/multidoc2dial_train_set.csv', sep='\\t', index=False)\n",
    "df_val.to_csv('dataset/multidoc2dial_validation_set.csv', sep='\\t', index=False)\n",
    "df_test.to_csv('dataset/multidoc2dial_test_set.csv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traininset(path_in, path_out):\n",
    "    dataset = []\n",
    "    df = pd.read_csv(path_in, sep='\\t')\n",
    "    for i in range(len(df)):\n",
    "        dataset.append({\n",
    "            'question+grounding': f\"{df['question_text'][i]} <sep> {df['grounding'][i]}\",\n",
    "            'utterance': f\"{df['utterance'][i]}\",\n",
    "            })\n",
    "    df_out = pd.DataFrame(dataset)\n",
    "    df_out.to_csv(path_out, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_traininset('dataset/multidoc2dial_train_set.csv', 'dataset/train_set.csv')\n",
    "generate_traininset('dataset/multidoc2dial_validation_set.csv', 'dataset/eval_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b00e76b2a62e0f40d8a6ff56467aaf5500da57d98eb1ca56dbad5a0a501eac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
