{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akBumB45ABYa",
        "outputId": "15730ed3-3ff7-40f0-f558-5cbe8c38167e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"alistvt\"\n",
        "!git config --global user.email \"alistvt@gmail.com\"\n",
        "\n",
        "%cd /content/drive/MyDrive/multidoc-conv-qa/src/retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dvS3v9W3m7t",
        "outputId": "087fb5bf-14e1-4a98-d4db-3b3b28815d1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/multidoc-conv-qa/src/retriever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCHw5gxO0Jx-",
        "outputId": "08972a8b-6f81-4044-e5a0-024586e23e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 14.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 20.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 325 kB 79.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 159 kB 79.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 680 kB 77.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 63.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 64.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 63.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 82.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 52.9 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.8.0 which is incompatible.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.2.4 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 175 kB 13.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -r ../../requirements.txt --quiet\n",
        "!pip install --quiet transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5akM0VXmzYku"
      },
      "source": [
        "# Document Retrival with Follow up Detector (DR.FUD) + DR. TEIT\n",
        "\n",
        "In this method we use a FCN to detect wheter a question is a follow up of the previous question, meaning that the document is the same of not. If the document is the same, we use the previous answer's document for this question also.\n",
        "\n",
        "We used LaBSE model for out embeddings. For computing title embedding similarities we used cosine similarity between query embeddings and each document's title embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9vpLyUkzWzO"
      },
      "source": [
        "# Dataset\n",
        "### Dataset Description\n",
        "\n",
        "- **mutldoc2dial_doc.json** contains the documents that are indexed by key `domain` and `doc_id` . Each document instance includes the following,\n",
        "\n",
        "  - `doc_id`: the ID of a document;\n",
        "  - `title`: the title of the document;\n",
        "  - `domain`: the domain of the document;\n",
        "  - `doc_text`: the text content of the document (without HTML markups);\n",
        "  - `doc_html_ts`: the document content with HTML markups and the annotated spans that are indicated by `text_id` attribute, which corresponds to `id_sp`.\n",
        "  - `doc_html_raw`: the document content with HTML markups and without span annotations.\n",
        "  - `spans`: key-value pairs of all spans in the document, with `id_sp` as key. Each span includes the following,\n",
        "    - `id_sp`: the id of a  span as noted by `text_id` in  `doc_html_ts`;\n",
        "    - `start_sp`/  `end_sp`: the start/end position of the text span in `doc_text`;\n",
        "    - `text_sp`: the text content of the span.\n",
        "    - `id_sec`: the id of the (sub)section (e.g. `<p>`) or title (`<h2>`) that contains the span.\n",
        "    - `start_sec` / `end_sec`: the start/end position of the (sub)section in `doc_text`.\n",
        "    - `text_sec`: the text of the (sub)section.\n",
        "    - `title`: the title of the (sub)section.\n",
        "    - `parent_titles`: the parent titles of the `title`.\n",
        "\n",
        "- **multidoc2dial_dial_train.json** and **multidoc2dial_dial_validation.json**  contain the training and dev split of dialogue data that are indexed by key `domain` . Please note: **For test split, we only include a dummy file in this version.**\n",
        "\n",
        "  Each dialogue instance includes the following,\n",
        "\n",
        "  - `dial_id`: the ID of a dialogue;\n",
        "  - `turns`: a list of dialogue turns. Each turn includes,\n",
        "    - `turn_id`: the time order of the turn;\n",
        "    - `role`: either \"agent\" or \"user\";READ\n",
        "    - `da`: dialogue act;\n",
        "    - `references`: a list of spans with `id_sp` ,  `label` and `doc_id`. `references` is empty if a turn is for indicating previous user query not answerable or irrelevant to the document. **Note** that labels \"*precondition*\"/\"*solution*\" are fuzzy annotations that indicate whether a span is for describing a conditional context or a solution.\n",
        "    - `utterance`: the human-generated utterance based on the dialogue scene.\n",
        "Downloading the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aEuwmS7O03CH"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('../../dataset/multidoc2dial/v1.0/multidoc2dial_doc.json', 'r') as f:\n",
        "    multidoc2dial_doc = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Wa65Cl1xUF"
      },
      "source": [
        "#### Extracting titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J0D-IV5H0vE4"
      },
      "outputs": [],
      "source": [
        "titles = []\n",
        "for doc_idx1 in multidoc2dial_doc['doc_data']:\n",
        "    for doc_idx2 in multidoc2dial_doc['doc_data'][doc_idx1]:\n",
        "        titles.append(doc_idx2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng4nYreI15Vn"
      },
      "source": [
        "#### Extracting document texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "96D34GnE1wQL"
      },
      "outputs": [],
      "source": [
        "doc_texts_train = []\n",
        "title_to_domain = {}\n",
        "for doc_idx1 in multidoc2dial_doc['doc_data']:\n",
        "    for doc_idx2 in multidoc2dial_doc['doc_data'][doc_idx1]:\n",
        "        doc_texts_train.append(multidoc2dial_doc['doc_data'][doc_idx1]\\\n",
        "                                          [doc_idx2]['doc_text'].strip())\n",
        "        title_to_domain[doc_idx2] = doc_idx1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4UoewSm0ICB"
      },
      "source": [
        "## Encoding the sentences\n",
        "We use the LaBSE which is a Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D1HTJrcK0RpF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "model_name = \"setu4993/LaBSE\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngG9eTIj0c01"
      },
      "source": [
        "### `get_embeddings`\n",
        "In this method we extract the **pooler output** (Last layer hidden-state of the first token of the sequence (classification token) after further processing through the layers used for the auxiliary pretraining task. E.g. for BERT-family of models, this returns the classification token after processing through a linear layer and a tanh activation function. The linear layer weights are trained from the next sentence prediction (classification) objective during pretraining)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QCTH88_t0ZD0"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(sentece):\n",
        "    \"\"\"\n",
        "    Return embeddings based on encoder model\n",
        "\n",
        "    :param sentence: input sentence(s)\n",
        "    :type sentence: str or list of strs\n",
        "    :return: embeddings\n",
        "    \"\"\"\n",
        "    tokenized = tokenizer(sentece,\n",
        "                                return_tensors=\"pt\",\n",
        "                                padding=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokenized)\n",
        "    \n",
        "    return np.squeeze(np.array(embeddings.pooler_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_VqBSNi4AaD"
      },
      "source": [
        "### Title embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hunKGBFq4C76"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "title_embeddings_file = 'doc_title_LaBSE_Embedding.npy'\n",
        "\n",
        "if not os.path.exists(title_embeddings_file):\n",
        "    title_embeddings = []\n",
        "    for title in tqdm(titles):\n",
        "        title_embeddings.append(get_embeddings(title))\n",
        "\n",
        "    with open(title_embeddings_file, 'wb') as f:\n",
        "        np.save(f, np.array(title_embeddings))\n",
        "else:\n",
        "    title_embeddings = np.load(title_embeddings_file)\n",
        "    title_embeddings = list(title_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CQmy3UiYiGG8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "title_to_embeddings_file = 'title_to_embeddings.pkl'\n",
        "\n",
        "if not os.path.exists(title_to_embeddings_file):\n",
        "    title_to_embeddings = {}\n",
        "    for title in tqdm(titles):\n",
        "        title_to_embeddings[title] = get_embeddings(title)\n",
        "    with open(title_to_embeddings_file, 'wb') as f:\n",
        "        pickle.dump(title_to_embeddings, f)\n",
        "else:\n",
        "    with open(title_to_embeddings_file, 'rb') as f:\n",
        "        title_to_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d42w3h1C2V1Q"
      },
      "source": [
        "## Calculating the IDF for each token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XjH-jRgs0fyv"
      },
      "outputs": [],
      "source": [
        "words_idf_file = 'IDFs.pkl'\n",
        "N_doc = len(doc_texts_train)\n",
        "\n",
        "if not os.path.exists(words_idf_file):\n",
        "    # First getting all distinct words in all documents\n",
        "    words = set()\n",
        "    doc_texts_train_tokenized = []\n",
        "    for doc in tqdm(doc_texts_train, desc=\"getting all words from documents\"):\n",
        "        tokenized_doc = [s.lower() for s in tokenizer.tokenize(doc)]\n",
        "        doc_texts_train_tokenized.append(tokenized_doc) \n",
        "        words = set(tokenized_doc).union(words)\n",
        "\n",
        "    # calculating each word IDF\n",
        "    words2IDF = {}\n",
        "    for word in tqdm(words, desc=\"calculating words IDF scores\"):\n",
        "        n_word = 0\n",
        "        for doc in doc_texts_train_tokenized:\n",
        "            if word in doc:\n",
        "                n_word += 1\n",
        "        words2IDF[word] = np.log(N_doc / (n_word + 1))\n",
        "\n",
        "    with open(words_idf_file, 'wb') as f:\n",
        "        pickle.dump(words2IDF, f)\n",
        "\n",
        "else:\n",
        "    with open(words_idf_file, 'rb') as f:\n",
        "        words2IDF = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6blMmmk2ugT",
        "outputId": "bac5ee03-ecce-4f7e-ee0d-dc20040568db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8446"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(words2IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CfcYwbdJ2zSN"
      },
      "outputs": [],
      "source": [
        "def calc_idf_score(sentence):\n",
        "    \"\"\"\n",
        "    Calculate the mean idf score for given sentence.\n",
        "    (used to understand the contribution of the knowledge of each question\n",
        "    questions with high frequent words are meaningless and we can ignore them\n",
        "    roughly, which is done by this score.)\n",
        "\n",
        "    :param sentence: input sentence\n",
        "    :type sentence: str\n",
        "    :return: mean idf score of sentence token\n",
        "    \"\"\"\n",
        "    tokenzied_sentence = [s.lower() for s in tokenizer.tokenize(sentence)]\n",
        "    score = 0\n",
        "    for token in tokenzied_sentence:\n",
        "        if token in words2IDF:\n",
        "            score += words2IDF[token]\n",
        "        else:\n",
        "            score += np.log(N_doc)\n",
        "    return score / len(tokenzied_sentence) if len(tokenzied_sentence) else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVN8XSp13LjU"
      },
      "source": [
        "## Constructing the Follow-up Dataset\n",
        "\n",
        "``` history | question | is_follow_up```\n",
        "\n",
        "is_follow_up: shows that the history's document is the same as the current question's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0wp6Mw7Q3LjV"
      },
      "outputs": [],
      "source": [
        "def combine_sentences(s1, s2):\n",
        "    separation_token = \" <SEP> \"\n",
        "    return s1 + separation_token + s2\n",
        "\n",
        "\n",
        "def construct_followup_dataset(filepath):\n",
        "    import json\n",
        "    with open(filepath, 'r') as f:\n",
        "        multidoc2dial_dial_train = json.load(f)\n",
        "    \n",
        "    historys = []\n",
        "    questions = []\n",
        "    combined = []\n",
        "    labels = []\n",
        "    prev_docs = []\n",
        "    current_docs = []\n",
        "    prev_answers = []\n",
        "    dial_ids = []\n",
        "    turn_ids = []\n",
        "    domains = []\n",
        "\n",
        "    for domain in multidoc2dial_dial_train['dial_data']:\n",
        "        for dial in multidoc2dial_dial_train['dial_data'][domain]:\n",
        "            prev_doc = ''\n",
        "            prev_question = ''\n",
        "            prev_answer = ''\n",
        "            for turn in dial['turns']:\n",
        "                if turn['role'] == \"user\":\n",
        "                    current_question = turn['utterance']\n",
        "                    historys.append(prev_question)\n",
        "                    questions.append(current_question)\n",
        "                    \n",
        "                    dial_ids.append(dial['dial_id'])\n",
        "                    turn_ids.append(turn['turn_id'])\n",
        "                    domains.append(domain)\n",
        "\n",
        "                    combined.append(combine_sentences(prev_question, current_question))\n",
        "\n",
        "                    current_doc = turn['references'][0]['doc_id']\n",
        "                    labels.append(int(current_doc==prev_doc))\n",
        "\n",
        "                    prev_docs.append(prev_doc)\n",
        "                    current_docs.append(current_doc)\n",
        "                    prev_answers.append(prev_answer)\n",
        "\n",
        "                    prev_doc, prev_question = current_doc, current_question\n",
        "                else:\n",
        "                    prev_answer = turn['utterance']\n",
        "                    \n",
        "    return dial_ids, turn_ids, domains, historys, questions, combined, labels, prev_docs, current_docs, prev_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iqDhkHSS3LjX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_dial_ids, train_turn_ids, train_domains, train_history, train_questions, train_combined, train_labels, train_prev_docs, train_current_docs, train_prev_answers = construct_followup_dataset('../../dataset/multidoc2dial/v1.0/multidoc2dial_dial_train.json')\n",
        "test_dial_ids, test_turn_ids, test_domains, test_history, test_questions, test_combined, test_labels, test_prev_docs, test_current_docs, test_prev_answers = construct_followup_dataset('../../dataset/multidoc2dial/v1.0/multidoc2dial_dial_validation.json')\n",
        "\n",
        "train_dict_dataset = {\"domain\": train_domains, \"turn_id\": train_turn_ids, \"dial_id\": train_dial_ids, \"history\":train_history, \"question\": train_questions, \"combined\": train_combined, \"followup\": train_labels, \"prev_doc\": train_prev_docs, \"current_doc\": train_current_docs, \"prev_answer\": train_prev_answers}\n",
        "test_dict_dataset = {\"domain\": test_domains, \"turn_id\": test_turn_ids, \"dial_id\": test_dial_ids , \"history\":test_history, \"question\": test_questions, \"combined\": test_combined, \"followup\": test_labels, \"prev_doc\": test_prev_docs, \"current_doc\": test_current_docs, \"prev_answer\": test_prev_answers}\n",
        "\n",
        "train_df = pd.DataFrame(train_dict_dataset)\n",
        "test_df = pd.DataFrame(test_dict_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o2ED0vIS-gur",
        "outputId": "c1bf9bf6-2c98-44b0-e74d-a18b8e1bd2bb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          domain  turn_id                           dial_id  \\\n",
              "0            dmv        1  1409501a35697e0ce68561e29577b90a   \n",
              "1            dmv        3  1409501a35697e0ce68561e29577b90a   \n",
              "2            dmv        5  1409501a35697e0ce68561e29577b90a   \n",
              "3            dmv        7  1409501a35697e0ce68561e29577b90a   \n",
              "4            dmv        9  1409501a35697e0ce68561e29577b90a   \n",
              "...          ...      ...                               ...   \n",
              "4491  studentaid        4  79f50cd4082141a57479195c61a0e7fc   \n",
              "4492  studentaid        6  79f50cd4082141a57479195c61a0e7fc   \n",
              "4493  studentaid        8  79f50cd4082141a57479195c61a0e7fc   \n",
              "4494  studentaid       10  79f50cd4082141a57479195c61a0e7fc   \n",
              "4495  studentaid       12  79f50cd4082141a57479195c61a0e7fc   \n",
              "\n",
              "                                                history  \\\n",
              "0                                                         \n",
              "1                My insurance ended so what should i do   \n",
              "2                      Don't do that I'll get insurance   \n",
              "3     I have, that is why I am here to clear that up...   \n",
              "4     Thank you so much. After looking through these...   \n",
              "...                                                 ...   \n",
              "4491  If I am totally and permanently disabled, can ...   \n",
              "4492                      In this case I would not like   \n",
              "4493  If I am a veteran whose application for discha...   \n",
              "4494  In addition, I need to learn about PSLF. What ...   \n",
              "4495                                               null   \n",
              "\n",
              "                                               question  \\\n",
              "0                My insurance ended so what should i do   \n",
              "1                      Don't do that I'll get insurance   \n",
              "2     I have, that is why I am here to clear that up...   \n",
              "3     Thank you so much. After looking through these...   \n",
              "4     Great. I think that I can found some bills, of...   \n",
              "...                                                 ...   \n",
              "4491                      In this case I would not like   \n",
              "4492  If I am a veteran whose application for discha...   \n",
              "4493  In addition, I need to learn about PSLF. What ...   \n",
              "4494                                               null   \n",
              "4495          If I did qualify what would it do for me?   \n",
              "\n",
              "                                               combined  followup  \\\n",
              "0          <SEP> My insurance ended so what should i do         0   \n",
              "1     My insurance ended so what should i do <SEP> D...         1   \n",
              "2     Don't do that I'll get insurance <SEP> I have,...         1   \n",
              "3     I have, that is why I am here to clear that up...         0   \n",
              "4     Thank you so much. After looking through these...         1   \n",
              "...                                                 ...       ...   \n",
              "4491  If I am totally and permanently disabled, can ...         1   \n",
              "4492  In this case I would not like <SEP> If I am a ...         1   \n",
              "4493  If I am a veteran whose application for discha...         0   \n",
              "4494  In addition, I need to learn about PSLF. What ...         1   \n",
              "4495  null <SEP> If I did qualify what would it do f...         1   \n",
              "\n",
              "                                               prev_doc  \\\n",
              "0                                                         \n",
              "1          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "2          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "3          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "4                   Help finding enough proof of ID#3_0   \n",
              "...                                                 ...   \n",
              "4491  Total and Permanent Disability Discharge | Fed...   \n",
              "4492  Total and Permanent Disability Discharge | Fed...   \n",
              "4493  Total and Permanent Disability Discharge | Fed...   \n",
              "4494  Public Service Loan Forgiveness | Federal Stud...   \n",
              "4495  Public Service Loan Forgiveness | Federal Stud...   \n",
              "\n",
              "                                            current_doc  \\\n",
              "0          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "1          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "2          Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "3                   Help finding enough proof of ID#3_0   \n",
              "4                   Help finding enough proof of ID#3_0   \n",
              "...                                                 ...   \n",
              "4491  Total and Permanent Disability Discharge | Fed...   \n",
              "4492  Total and Permanent Disability Discharge | Fed...   \n",
              "4493  Public Service Loan Forgiveness | Federal Stud...   \n",
              "4494  Public Service Loan Forgiveness | Federal Stud...   \n",
              "4495  Public Service Loan Forgiveness | Federal Stud...   \n",
              "\n",
              "                                            prev_answer  \n",
              "0                                                        \n",
              "1     You will need to get insurance or we will susp...  \n",
              "2     Okay, have you received a letter from the DMV ...  \n",
              "3                        Okay, we can take care of that  \n",
              "4     Sure, it is. You can contact your college and ...  \n",
              "...                                                 ...  \n",
              "4491                want to qualify for a TPD download?  \n",
              "4492   Unfortunately, no relevant information is found.  \n",
              "4493  in this case it is not subject to a post-disch...  \n",
              "4494  Are you employed by a U.S. federal, state, loc...  \n",
              "4495                       You do not qualify for PSLF.  \n",
              "\n",
              "[4496 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fede5c42-30cd-45bb-b239-8dfcca3d21c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>turn_id</th>\n",
              "      <th>dial_id</th>\n",
              "      <th>history</th>\n",
              "      <th>question</th>\n",
              "      <th>combined</th>\n",
              "      <th>followup</th>\n",
              "      <th>prev_doc</th>\n",
              "      <th>current_doc</th>\n",
              "      <th>prev_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dmv</td>\n",
              "      <td>1</td>\n",
              "      <td>1409501a35697e0ce68561e29577b90a</td>\n",
              "      <td></td>\n",
              "      <td>My insurance ended so what should i do</td>\n",
              "      <td>&lt;SEP&gt; My insurance ended so what should i do</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dmv</td>\n",
              "      <td>3</td>\n",
              "      <td>1409501a35697e0ce68561e29577b90a</td>\n",
              "      <td>My insurance ended so what should i do</td>\n",
              "      <td>Don't do that I'll get insurance</td>\n",
              "      <td>My insurance ended so what should i do &lt;SEP&gt; D...</td>\n",
              "      <td>1</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>You will need to get insurance or we will susp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dmv</td>\n",
              "      <td>5</td>\n",
              "      <td>1409501a35697e0ce68561e29577b90a</td>\n",
              "      <td>Don't do that I'll get insurance</td>\n",
              "      <td>I have, that is why I am here to clear that up...</td>\n",
              "      <td>Don't do that I'll get insurance &lt;SEP&gt; I have,...</td>\n",
              "      <td>1</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Okay, have you received a letter from the DMV ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dmv</td>\n",
              "      <td>7</td>\n",
              "      <td>1409501a35697e0ce68561e29577b90a</td>\n",
              "      <td>I have, that is why I am here to clear that up...</td>\n",
              "      <td>Thank you so much. After looking through these...</td>\n",
              "      <td>I have, that is why I am here to clear that up...</td>\n",
              "      <td>0</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Help finding enough proof of ID#3_0</td>\n",
              "      <td>Okay, we can take care of that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dmv</td>\n",
              "      <td>9</td>\n",
              "      <td>1409501a35697e0ce68561e29577b90a</td>\n",
              "      <td>Thank you so much. After looking through these...</td>\n",
              "      <td>Great. I think that I can found some bills, of...</td>\n",
              "      <td>Thank you so much. After looking through these...</td>\n",
              "      <td>1</td>\n",
              "      <td>Help finding enough proof of ID#3_0</td>\n",
              "      <td>Help finding enough proof of ID#3_0</td>\n",
              "      <td>Sure, it is. You can contact your college and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>studentaid</td>\n",
              "      <td>4</td>\n",
              "      <td>79f50cd4082141a57479195c61a0e7fc</td>\n",
              "      <td>If I am totally and permanently disabled, can ...</td>\n",
              "      <td>In this case I would not like</td>\n",
              "      <td>If I am totally and permanently disabled, can ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Total and Permanent Disability Discharge | Fed...</td>\n",
              "      <td>Total and Permanent Disability Discharge | Fed...</td>\n",
              "      <td>want to qualify for a TPD download?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4492</th>\n",
              "      <td>studentaid</td>\n",
              "      <td>6</td>\n",
              "      <td>79f50cd4082141a57479195c61a0e7fc</td>\n",
              "      <td>In this case I would not like</td>\n",
              "      <td>If I am a veteran whose application for discha...</td>\n",
              "      <td>In this case I would not like &lt;SEP&gt; If I am a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Total and Permanent Disability Discharge | Fed...</td>\n",
              "      <td>Total and Permanent Disability Discharge | Fed...</td>\n",
              "      <td>Unfortunately, no relevant information is found.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4493</th>\n",
              "      <td>studentaid</td>\n",
              "      <td>8</td>\n",
              "      <td>79f50cd4082141a57479195c61a0e7fc</td>\n",
              "      <td>If I am a veteran whose application for discha...</td>\n",
              "      <td>In addition, I need to learn about PSLF. What ...</td>\n",
              "      <td>If I am a veteran whose application for discha...</td>\n",
              "      <td>0</td>\n",
              "      <td>Total and Permanent Disability Discharge | Fed...</td>\n",
              "      <td>Public Service Loan Forgiveness | Federal Stud...</td>\n",
              "      <td>in this case it is not subject to a post-disch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4494</th>\n",
              "      <td>studentaid</td>\n",
              "      <td>10</td>\n",
              "      <td>79f50cd4082141a57479195c61a0e7fc</td>\n",
              "      <td>In addition, I need to learn about PSLF. What ...</td>\n",
              "      <td>null</td>\n",
              "      <td>In addition, I need to learn about PSLF. What ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Public Service Loan Forgiveness | Federal Stud...</td>\n",
              "      <td>Public Service Loan Forgiveness | Federal Stud...</td>\n",
              "      <td>Are you employed by a U.S. federal, state, loc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>studentaid</td>\n",
              "      <td>12</td>\n",
              "      <td>79f50cd4082141a57479195c61a0e7fc</td>\n",
              "      <td>null</td>\n",
              "      <td>If I did qualify what would it do for me?</td>\n",
              "      <td>null &lt;SEP&gt; If I did qualify what would it do f...</td>\n",
              "      <td>1</td>\n",
              "      <td>Public Service Loan Forgiveness | Federal Stud...</td>\n",
              "      <td>Public Service Loan Forgiveness | Federal Stud...</td>\n",
              "      <td>You do not qualify for PSLF.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4496 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fede5c42-30cd-45bb-b239-8dfcca3d21c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fede5c42-30cd-45bb-b239-8dfcca3d21c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fede5c42-30cd-45bb-b239-8dfcca3d21c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNPG-waE3LjX",
        "outputId": "7ee8eea8-9f50-4fb4-b6e8-36becc47aa2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "max([len(x[\"combined\"].split()) for _, x in test_df.iterrows()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "vYbgJuaS3LjZ",
        "outputId": "1037b216-2f64-4343-fe22-d538e14d416d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 history  \\\n",
              "0                                                          \n",
              "1      Hello, I forgot o update my address, can you h...   \n",
              "2                   Can I do my DMV transactions online?   \n",
              "3      You've got it. Another query about DMV. What h...   \n",
              "4                 Besides that, will I receive a notice?   \n",
              "...                                                  ...   \n",
              "23394  By the way, who can I contact to give me infor...   \n",
              "23395  What if I've fallen behind on one or more loan...   \n",
              "23396  I have another question regarding the Military...   \n",
              "23397  something else I want to ask about FAFSA. What...   \n",
              "23398                  How can I make a payment by post?   \n",
              "\n",
              "                                                question  \\\n",
              "0      Hello, I forgot o update my address, can you h...   \n",
              "1                   Can I do my DMV transactions online?   \n",
              "2      You've got it. Another query about DMV. What h...   \n",
              "3                 Besides that, will I receive a notice?   \n",
              "4                           If you submit the affidavit?   \n",
              "...                                                  ...   \n",
              "23394  What if I've fallen behind on one or more loan...   \n",
              "23395  I have another question regarding the Military...   \n",
              "23396  something else I want to ask about FAFSA. What...   \n",
              "23397                  How can I make a payment by post?   \n",
              "23398                  Can you forgive the student loan?   \n",
              "\n",
              "                                                combined  followup  \\\n",
              "0       <SEP> Hello, I forgot o update my address, ca...         0   \n",
              "1      Hello, I forgot o update my address, can you h...         1   \n",
              "2      Can I do my DMV transactions online? <SEP> You...         0   \n",
              "3      You've got it. Another query about DMV. What h...         1   \n",
              "4      Besides that, will I receive a notice? <SEP> I...         1   \n",
              "...                                                  ...       ...   \n",
              "23394  By the way, who can I contact to give me infor...         0   \n",
              "23395  What if I've fallen behind on one or more loan...         0   \n",
              "23396  I have another question regarding the Military...         0   \n",
              "23397  something else I want to ask about FAFSA. What...         1   \n",
              "23398  How can I make a payment by post? <SEP> Can yo...         1   \n",
              "\n",
              "                                                prev_doc  \\\n",
              "0                                                          \n",
              "1           Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "2           Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "3      Registration suspensions for failure to pay to...   \n",
              "4      Registration suspensions for failure to pay to...   \n",
              "...                                                  ...   \n",
              "23394           Loan Servicers | Federal Student Aid#1_0   \n",
              "23395   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "23396   Student Loan Deferment | Federal Student Aid#1_0   \n",
              "23397   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "23398   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "\n",
              "                                             current_doc  \\\n",
              "0           Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "1           Top 5 DMV Mistakes and How to Avoid Them#3_0   \n",
              "2      Registration suspensions for failure to pay to...   \n",
              "3      Registration suspensions for failure to pay to...   \n",
              "4      Registration suspensions for failure to pay to...   \n",
              "...                                                  ...   \n",
              "23394   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "23395   Student Loan Deferment | Federal Student Aid#1_0   \n",
              "23396   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "23397   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "23398   Student Loan Repayment | Federal Student Aid#1_0   \n",
              "\n",
              "                                             prev_answer  \n",
              "0                                                         \n",
              "1      hi, you have to report any change of address t...  \n",
              "2      Yes, you can sign up for MyDMV for all the onl...  \n",
              "3      the suspension is placed on hold pending the o...  \n",
              "4       the NYS Department of Motor Vehicles , \" DMV ...  \n",
              "...                                                  ...  \n",
              "23394  Your school's financial aid office must have t...  \n",
              "23395  One thing you definitely want to avoid is goin...  \n",
              "23396  You will have to complete the Military Service...  \n",
              "23397  contact your loan servicer to find out your op...  \n",
              "23398  you must contact your loan servicer for the ma...  \n",
              "\n",
              "[23399 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54cfe5e7-3e03-4c94-89b5-bad318e6babf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>history</th>\n",
              "      <th>question</th>\n",
              "      <th>combined</th>\n",
              "      <th>followup</th>\n",
              "      <th>prev_doc</th>\n",
              "      <th>current_doc</th>\n",
              "      <th>prev_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>Hello, I forgot o update my address, can you h...</td>\n",
              "      <td>&lt;SEP&gt; Hello, I forgot o update my address, ca...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hello, I forgot o update my address, can you h...</td>\n",
              "      <td>Can I do my DMV transactions online?</td>\n",
              "      <td>Hello, I forgot o update my address, can you h...</td>\n",
              "      <td>1</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>hi, you have to report any change of address t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can I do my DMV transactions online?</td>\n",
              "      <td>You've got it. Another query about DMV. What h...</td>\n",
              "      <td>Can I do my DMV transactions online? &lt;SEP&gt; You...</td>\n",
              "      <td>0</td>\n",
              "      <td>Top 5 DMV Mistakes and How to Avoid Them#3_0</td>\n",
              "      <td>Registration suspensions for failure to pay to...</td>\n",
              "      <td>Yes, you can sign up for MyDMV for all the onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You've got it. Another query about DMV. What h...</td>\n",
              "      <td>Besides that, will I receive a notice?</td>\n",
              "      <td>You've got it. Another query about DMV. What h...</td>\n",
              "      <td>1</td>\n",
              "      <td>Registration suspensions for failure to pay to...</td>\n",
              "      <td>Registration suspensions for failure to pay to...</td>\n",
              "      <td>the suspension is placed on hold pending the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Besides that, will I receive a notice?</td>\n",
              "      <td>If you submit the affidavit?</td>\n",
              "      <td>Besides that, will I receive a notice? &lt;SEP&gt; I...</td>\n",
              "      <td>1</td>\n",
              "      <td>Registration suspensions for failure to pay to...</td>\n",
              "      <td>Registration suspensions for failure to pay to...</td>\n",
              "      <td>the NYS Department of Motor Vehicles , \" DMV ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23394</th>\n",
              "      <td>By the way, who can I contact to give me infor...</td>\n",
              "      <td>What if I've fallen behind on one or more loan...</td>\n",
              "      <td>By the way, who can I contact to give me infor...</td>\n",
              "      <td>0</td>\n",
              "      <td>Loan Servicers | Federal Student Aid#1_0</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>Your school's financial aid office must have t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23395</th>\n",
              "      <td>What if I've fallen behind on one or more loan...</td>\n",
              "      <td>I have another question regarding the Military...</td>\n",
              "      <td>What if I've fallen behind on one or more loan...</td>\n",
              "      <td>0</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>Student Loan Deferment | Federal Student Aid#1_0</td>\n",
              "      <td>One thing you definitely want to avoid is goin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23396</th>\n",
              "      <td>I have another question regarding the Military...</td>\n",
              "      <td>something else I want to ask about FAFSA. What...</td>\n",
              "      <td>I have another question regarding the Military...</td>\n",
              "      <td>0</td>\n",
              "      <td>Student Loan Deferment | Federal Student Aid#1_0</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>You will have to complete the Military Service...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23397</th>\n",
              "      <td>something else I want to ask about FAFSA. What...</td>\n",
              "      <td>How can I make a payment by post?</td>\n",
              "      <td>something else I want to ask about FAFSA. What...</td>\n",
              "      <td>1</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>contact your loan servicer to find out your op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23398</th>\n",
              "      <td>How can I make a payment by post?</td>\n",
              "      <td>Can you forgive the student loan?</td>\n",
              "      <td>How can I make a payment by post? &lt;SEP&gt; Can yo...</td>\n",
              "      <td>1</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>Student Loan Repayment | Federal Student Aid#1_0</td>\n",
              "      <td>you must contact your loan servicer for the ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23399 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54cfe5e7-3e03-4c94-89b5-bad318e6babf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54cfe5e7-3e03-4c94-89b5-bad318e6babf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54cfe5e7-3e03-4c94-89b5-bad318e6babf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gF0ziqxJ3Lja"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples, prediction=False, cuda=False):\n",
        "    if prediction:\n",
        "        tokenized = tokenizer(examples['combined'], max_length=128, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
        "    else:\n",
        "        tokenized = tokenizer(examples['combined'], max_length=128, padding=\"max_length\", truncation=True)\n",
        "    if cuda:\n",
        "        tokenized_cuda = {}\n",
        "        for key, value in tokenized.items():\n",
        "            tokenized_cuda[key] = value.cuda()\n",
        "        return tokenized_cuda\n",
        "    else:\n",
        "        return tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3IbMkVd3Lja"
      },
      "source": [
        "### constructing dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4d6870f987f6424eb0810ef9f1cac3c2",
            "e91f634b4ac64907b6cbc0278df8dd69",
            "95d4713c357e4986abd6b5cbf51752c7",
            "c711a512e578435f9e1bb5dd83cb1b8d",
            "7346eab318024c9287da2c543c42cb0a",
            "1450ff44f4274dbc839fb1d23b7221bf",
            "0d18bacc7f484c41ac55a0c172646493",
            "1b6f506d27db4ae1adca5fed43ee2719",
            "d98e1f84a4224ac2b490c92f3d194fea",
            "f2d524d60fe649a7ba6a3ddb8169a970",
            "da6eb447a73648b6a8945aaa4b239cb5",
            "cc24443458a54495b33a0c7f7763bb5c",
            "d6b365157aa94949a53b600ab41d4f2b",
            "c100142a51c8492d8c82bc0ba277420d",
            "6482b54cfe274659b5bc6f896fd51675",
            "a1789b6c64d24221a8fd74e2d1425cd8",
            "1e2fe805e2ec40b59a73b15187c96c94",
            "17ff5a6cf7f24391bc3f1e275cc307c3",
            "41c622fa2d154766ab283dba7a6366d7",
            "afda3c88f3334d7895aa642167c45beb",
            "5d2ec52410a94156ae7d850a9e0f69a3",
            "8932c110b4ec412f957bd01516ba1b5a"
          ]
        },
        "id": "n89j9i8A3Ljb",
        "outputId": "90a19896-2436-4fd9-956f-7887d5800de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x7f2d8dbc0b90> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d6870f987f6424eb0810ef9f1cac3c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc24443458a54495b33a0c7f7763bb5c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "tokenized_trainset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_testset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_trainset = tokenized_trainset.rename_column(\"followup\", \"label\")\n",
        "tokenized_testset = tokenized_testset.rename_column(\"followup\", \"label\")\n",
        "\n",
        "fud_dataset = DatasetDict()\n",
        "\n",
        "fud_dataset['train'] = tokenized_trainset\n",
        "fud_dataset['validation'] = tokenized_testset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtOJcbeo5rBQ"
      },
      "source": [
        "# Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr3Qbox83Ljc"
      },
      "source": [
        "## FCN based on [cls]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zRT_9kl3Ljd"
      },
      "source": [
        "### AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a classification method on the questions to decide the relationship between the previous question and current question.\n",
        "In the dataset provided to us, previous turn documents are predefined, meaning that we are aware of the previous documents, therefore, if the prediction predicts that current question's document is the same as the previous, we don't need to retrieve a document and we give the previous doc_id."
      ],
      "metadata": {
        "id": "0oFuQ6Tq8eoC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsHE7D873Ljd"
      },
      "source": [
        "#### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRkLfGS43Lje"
      },
      "outputs": [],
      "source": [
        "model_name = \"setu4993/LaBSE\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "fudnet_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "fudnet_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcI4P0Lt3Lje"
      },
      "source": [
        "#### metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "3347e9ff5058477c95f3d885a90d1c86",
            "7b6f0cf917ec49cd9e1a79f095a32c79",
            "0bf60789e6bf4003b75dff517dd265b3",
            "592629bce15f4518801cf80f1d06f813",
            "8e3f8511dbb34eef8383b3d6a8a5e518",
            "1e96fd6eaba94c6abb8a3430be5dcdeb",
            "5ed0c6780af44696b1aee67f1886bc05",
            "cac0a5e3bf70410e84d7962d6bff575f",
            "f82fdad7e54148909c3ff564f4adab86",
            "eecf6d418527465f82f2099bca0e020a",
            "349af9aa536a4386b99f3278a0503e2a"
          ]
        },
        "id": "HgLwYYuQ3Ljf",
        "outputId": "d73bc3ee-f88d-4747-fba8-52db401bea37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3347e9ff5058477c95f3d885a90d1c86"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDy2n4oi3Ljg"
      },
      "source": [
        "#### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-eckBPu3Ljg"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/home/',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy ='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    # auto_find_batch_size=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=fudnet_model,\n",
        "    args=training_args,\n",
        "    train_dataset=fud_dataset['train'],\n",
        "    eval_dataset=fud_dataset['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "aev9XuyUA0DA",
        "outputId": "63a28b0d-73c1-4827-ad9d-93230cabe373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: combined, current_doc, prev_answer, history, question, prev_doc. If combined, current_doc, prev_answer, history, question, prev_doc are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 23399\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1464\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1464' max='1464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1464/1464 12:54, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.172100</td>\n",
              "      <td>0.144127</td>\n",
              "      <td>0.949066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.094800</td>\n",
              "      <td>0.137107</td>\n",
              "      <td>0.954404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: combined, current_doc, prev_answer, history, question, prev_doc. If combined, current_doc, prev_answer, history, question, prev_doc are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4496\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /home/checkpoint-732\n",
            "Configuration saved in /home/checkpoint-732/config.json\n",
            "Model weights saved in /home/checkpoint-732/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: combined, current_doc, prev_answer, history, question, prev_doc. If combined, current_doc, prev_answer, history, question, prev_doc are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4496\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /home/checkpoint-1464\n",
            "Configuration saved in /home/checkpoint-1464/config.json\n",
            "Model weights saved in /home/checkpoint-1464/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /home/checkpoint-1464 (score: 0.13710716366767883).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1464, training_loss=0.1559999535481135, metrics={'train_runtime': 779.0272, 'train_samples_per_second': 60.072, 'train_steps_per_second': 1.879, 'total_flos': 3078267792184320.0, 'train_loss': 0.1559999535481135, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_fudnet = tokenizer\n",
        "fudnet_model = AutoModelForSequenceClassification.from_pretrained('alistvt/fudnet')"
      ],
      "metadata": {
        "id": "A7CEJNzDo7Gr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "fudnet_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaP0w7pMpLis",
        "outputId": "e640dc5e-6670-41fb-b5ad-549e80dfa34c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(501153, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuhM4K4J1E3Y"
      },
      "source": [
        "### DR. TEIT*\n",
        "\n",
        "In this method we used two scoring measure and aggregate them by a convex combination as below:\n",
        "$$\n",
        "λ*Similiarity_{Title Embedding} + (1-λ)*Similiarity_{TextIDF}\n",
        "$$\n",
        "\n",
        "We used LaBSE model for our embeddings. For computing title embedding similarities we used cosine similarity between query embeddings and each document's title embedding.\n",
        "\n",
        "For the second part we used character-level (2gram to 8gram). We also trained our TF-IDF transformation matrix on the Multidoc2dial2022 documnets.\n",
        "\n",
        "**NOTE: In `predict_DR_TEIT` you may see a diffrent notation (`alpha`) but they are the same.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q251xG1B1f2I"
      },
      "source": [
        "#### TF-IDF Transformation Matrix Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "BoNS99AY1LZl"
      },
      "outputs": [],
      "source": [
        "doc_texts_train = []\n",
        "doc_idx_train = []\n",
        "\n",
        "doc_domains = {}\n",
        "# for domain, domain_data in multidoc2dial_doc['doc_data'].items():\n",
        "#     for doc_id, doc_data in domain_data.items():\n",
        "#         processed_section_ids = []\n",
        "#         for span_id, span in doc_data['spans'].items():\n",
        "#             if span['id_sec'] not in processed_section_ids:\n",
        "#                 processed_section_ids.append(span['id_sec'])\n",
        "#                 section_text = span['text_sec']\n",
        "#                 doc_texts_train.append(section_text)\n",
        "#                 doc_idx_train.append(doc_id)\n",
        "\n",
        "for domain in multidoc2dial_doc['doc_data']:\n",
        "    for doc_idx2 in multidoc2dial_doc['doc_data'][domain]:\n",
        "        doc_texts_train.append(multidoc2dial_doc['doc_data'][domain]\\\n",
        "                                          [doc_idx2]['doc_text'].strip())\n",
        "        doc_idx_train.append(doc_idx2)\n",
        "        doc_domains[doc_idx2] = domain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(doc_texts_train), len(doc_idx_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtoYKnZtya2r",
        "outputId": "7342dac2-fefd-4ed6-956a-3cf00dccbf7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "488 488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stopwords removal and preprocessing"
      ],
      "metadata": {
        "id": "b1CL44Eg26St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "new_doc_texts_train = []\n",
        "\n",
        "all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))\n",
        "\n",
        "for text in tqdm(doc_texts_train):\n",
        "    text = text.lower()\n",
        "    text_tokens = word_tokenize(text)\n",
        "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
        "    new_doc_texts_train.append(\" \".join(tokens_without_sw))\n",
        "\n",
        "# print(tokens_without_sw)\n",
        "doc_texts_train = new_doc_texts_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNJ0jcvV3F4L",
        "outputId": "151b1d7d-8cf6-415c-ee4e-e12bc6762f08"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.63.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "100%|██████████| 488/488 [00:04<00:00, 101.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wZs4IB7x1S68"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfVectorizer = TfidfVectorizer(strip_accents=None,\n",
        "                                 analyzer='char_wb',\n",
        "                                 ngram_range=(3, 6),\n",
        "                                 norm='l2',\n",
        "                                 use_idf=True,\n",
        "                                 smooth_idf=True)\n",
        "tfidf_wm = tfidfVectorizer.fit_transform(doc_texts_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU-xRf0V3Ljl",
        "outputId": "da1b3746-385f-44e4-cb0f-1481ae60246b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8398"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "len(tfidfVectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B3p34wgW1emS"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('tfidfVectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidfVectorizer, f)\n",
        "\n",
        "with open('tfidf_wm.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf_wm, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30VbDrMH15l6"
      },
      "source": [
        "#### DR. TEIT\n",
        "\n",
        "the input is consisted of a list of queries, which is the current question and its history turns.\n",
        "for each of the questions, we compute two similarity score for each of our documents, one of them is based on the pretrained LM and the other on is based on character level matching. Both of these scores will be weighted by a coefficient which is the `idf_score` of the query, defining how much meaning does the query contain. Then these scores will be summed up in a convex manner and the final matching score with all documents is computed. We return the result by sorting these scores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict_DR_TEIT(queries, k=1, alpha=10):\n",
        "#     \"\"\"\n",
        "#     Predict which document is matched to the given query.\n",
        "\n",
        "#     :param queries: input queries in time reversed order (latest first)\n",
        "#     :type queries: str (or list of strs)\n",
        "#     :param k: number of returning docs\n",
        "#     :type k: int \n",
        "#     :return: return the document names and accuracies\n",
        "#     \"\"\"\n",
        "\n",
        "#     idf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "#     tfidf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "#     coef_sum = 0\n",
        "#     for i, query in enumerate(queries):\n",
        "#         query_embd = get_embeddings(query)\n",
        "#         query_sim = list(map(lambda x: np.dot(x, query_embd) /\n",
        "#                             (np.linalg.norm(query_embd) * np.linalg.norm(x)),\n",
        "#                             title_embeddings))\n",
        "#         query_sim = np.array(query_sim)\n",
        "#         coef = 2**(-i) * calc_idf_score(query)\n",
        "#         coef = calc_idf_score(query)\n",
        "#         coef_sum += coef\n",
        "\n",
        "#         idf_score += coef * query_sim\n",
        "#         tfidf_score += coef * np.squeeze(np.asarray(tfidf_wm @ tfidfVectorizer.transform([query]).todense().T))\n",
        "\n",
        "#     scores = (idf_score + alpha * tfidf_score) / coef_sum\n",
        "#     best_k_idx = scores.argsort()[::-1][:k]\n",
        "#     scores = scores[best_k_idx]\n",
        "#     predictions = list(map(lambda x: titles[x], best_k_idx))\n",
        "#     return (scores, predictions)"
      ],
      "metadata": {
        "id": "izi4TOAiuqcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7ELrMT4g17vc"
      },
      "outputs": [],
      "source": [
        "def predict_DR_TEIT(queries, k=1, alpha=10):\n",
        "    \"\"\"\n",
        "    Predict which document is matched to the given query.\n",
        "\n",
        "    :param queries: input queries in time reversed order (latest first)\n",
        "    :type queries: str (or list of strs)\n",
        "    :param k: number of returning docs\n",
        "    :type k: int \n",
        "    :return: return the document names and accuracies\n",
        "    \"\"\"\n",
        "\n",
        "    idf_score = np.array(list(map(lambda x: 0.0, doc_idx_train)))\n",
        "    # idf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "    tfidf_score = np.array(list(map(lambda x: 0.0, doc_idx_train)))\n",
        "    # tfidf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "    coef_sum = 0\n",
        "    for i, query in enumerate(queries):\n",
        "        # query_embd = get_embeddings(query)\n",
        "        # query_sim = list(map(lambda x: np.dot(x, query_embd) /\n",
        "        #                     (np.linalg.norm(query_embd) * np.linalg.norm(x)),\n",
        "        #                     title_embeddings))\n",
        "        # query_sim = np.array(query_sim)\n",
        "        # coef = 2**(-i) * calc_idf_score(query)\n",
        "        coef = calc_idf_score(query)\n",
        "        coef_sum += coef\n",
        "\n",
        "        # idf_score += coef * query_sim\n",
        "        tfidf_score += coef * np.squeeze(np.asarray(tfidf_wm @ tfidfVectorizer.transform([query]).todense().T))\n",
        "\n",
        "    scores = (tfidf_score) / coef_sum\n",
        "    best_k_idx = scores.argsort()[::-1][:k]\n",
        "    scores = scores[best_k_idx]\n",
        "    predictions = list(map(lambda x: doc_idx_train[x], best_k_idx))\n",
        "    # predictions = list(map(lambda x: titles[x], best_k_idx))\n",
        "    return (scores, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVPAssp-52SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FUDNet + DR. TEIT"
      ],
      "metadata": {
        "id": "oPC_VWvd407M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_FUDNet_DR_TEIT(data, k=1):\n",
        "    inputs = tokenize_function(data, prediction=True, cuda=True)\n",
        "    outputs = fudnet_model(**inputs)\n",
        "    is_followup = bool(torch.argmax(outputs.logits))\n",
        "    \n",
        "    if is_followup:\n",
        "        dr_scores, dr_predictions = predict_DR_TEIT([data['prev_answer'], data['question'], data['history']], k=k)\n",
        "        return dr_predictions\n",
        "    else:\n",
        "        dr_scores, dr_predictions = predict_DR_TEIT([data['question']], k=k)\n",
        "        return dr_predictions"
      ],
      "metadata": {
        "id": "FOIe5Tn643ZO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.loc[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YCZ4JOhRoyQ",
        "outputId": "8b3eb94d-f39b-4961-9808-d4c82ba01908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "history                         Don't do that I'll get insurance\n",
              "question       I have, that is why I am here to clear that up...\n",
              "combined       Don't do that I'll get insurance <SEP> I have,...\n",
              "followup                                                       1\n",
              "prev_doc            Top 5 DMV Mistakes and How to Avoid Them#3_0\n",
              "current_doc         Top 5 DMV Mistakes and How to Avoid Them#3_0\n",
              "prev_answer    Okay, have you received a letter from the DMV ...\n",
              "Name: 2, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_FUDNet_DR_TEIT(test_df.loc[2], k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlqEPT-y_Jtb",
        "outputId": "e54d3192-67a9-435e-a5a1-9d133df12bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Top 5 DMV Mistakes and How to Avoid Them#3_0',\n",
              " 'Respond to DMV insurance letters and orders#3_0',\n",
              " 'How to change your address#1_0',\n",
              " 'Insurance lapses#3_0',\n",
              " 'Information about transaction entries#3_0']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN + FUDNet + DR. TEIT"
      ],
      "metadata": {
        "id": "R6Ju0mlj09Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting span embeddings"
      ],
      "metadata": {
        "id": "3ce2XzKF1Gp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def construct_span_doc_id():\n",
        "    spans = []\n",
        "    doc_ids = []\n",
        "    domains = []\n",
        "    for domain in tqdm(multidoc2dial_doc['doc_data'], desc=\"iterating over domains\"):\n",
        "        for doc_id in tqdm(multidoc2dial_doc['doc_data'][domain], desc=\"iterating over doc_ids\"):\n",
        "            doc = multidoc2dial_doc['doc_data'][domain][doc_id]\n",
        "\n",
        "            spans.append(doc[\"title\"])\n",
        "            doc_ids.append(doc_id)\n",
        "            domains.append(domain)\n",
        "            for span_id, span in doc[\"spans\"].items():\n",
        "                spans.append(span[\"text_sp\"])\n",
        "                doc_ids.append(doc_id)\n",
        "                domains.append(domain)\n",
        "    assert len(spans) == len(doc_ids) == len(domains), \"inconsistency\"\n",
        "    return spans, doc_ids, domains\n",
        "\n",
        "spans, doc_ids, domains = construct_span_doc_id()"
      ],
      "metadata": {
        "id": "hS8bgd0f3Np7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f93f30-bec1-444a-aade-db71831eba8b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "iterating over domains:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "iterating over doc_ids: 100%|██████████| 109/109 [00:00<00:00, 23992.61it/s]\n",
            "\n",
            "iterating over doc_ids: 100%|██████████| 138/138 [00:00<00:00, 23780.36it/s]\n",
            "\n",
            "iterating over doc_ids: 100%|██████████| 149/149 [00:00<00:00, 22460.87it/s]\n",
            "\n",
            "iterating over doc_ids: 100%|██████████| 92/92 [00:00<00:00, 19228.42it/s]\n",
            "iterating over domains: 100%|██████████| 4/4 [00:00<00:00, 50.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "span_embeddings_file = 'span_embeddings_labse.npy'\n",
        "\n",
        "if not os.path.exists(span_embeddings_file):\n",
        "    span_embeddings = []\n",
        "    for span in tqdm(spans):\n",
        "        span_embeddings.append(get_embeddings(span))\n",
        "\n",
        "    with open(span_embeddings_file, 'wb') as f:\n",
        "        np.save(f, np.array(span_embeddings))\n",
        "else:\n",
        "    span_embeddings = np.load(span_embeddings_file)\n",
        "    span_embeddings = list(span_embeddings)"
      ],
      "metadata": {
        "id": "nsAPhHam1D7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predictor"
      ],
      "metadata": {
        "id": "nkPVjtFr1YFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nearests_doc_ids(text, k=None):\n",
        "    x_embed = get_embeddings(text).reshape(1, -1)\n",
        "    neighs = doc_predictor.kneighbors(x_embed)\n",
        "    return [doc_ids[x] for x in neighs[1][0,:]]"
      ],
      "metadata": {
        "id": "1OWpfm4n1X0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_KNN_FUDNet_DR_TEIT(queries, k=1, alpha=10):\n",
        "    \"\"\"\n",
        "    Predict which document is matched to the given query.\n",
        "\n",
        "    :param queries: input queries in time reversed order (latest first)\n",
        "    :type queries: str (or list of strs)\n",
        "    :param k: number of returning docs\n",
        "    :type k: int \n",
        "    :return: return the document names and accuracies\n",
        "    \"\"\"\n",
        "\n",
        "    idf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "    tfidf_score = np.array(list(map(lambda x: 0.0, title_embeddings)))\n",
        "    coef_sum = 0\n",
        "    for i, query in enumerate(queries):\n",
        "        query_embd = get_embeddings(query)\n",
        "        query_sim = list(map(lambda x: np.dot(x, query_embd) /\n",
        "                            (np.linalg.norm(query_embd) * np.linalg.norm(x)),\n",
        "                            title_embeddings))\n",
        "        query_sim = np.array(query_sim)\n",
        "        # coef = 2**(-i) * calc_idf_score(query)\n",
        "        coef = calc_idf_score(query)\n",
        "        coef_sum += coef\n",
        "\n",
        "        idf_score += coef * query_sim\n",
        "        tfidf_score += coef * np.squeeze(np.asarray(tfidf_wm @ tfidfVectorizer.transform([query]).todense().T))\n",
        "\n",
        "    scores = (1 * idf_score + alpha * tfidf_score) / coef_sum\n",
        "    best_k_idx = scores.argsort()[::-1][:k]\n",
        "    scores = scores[best_k_idx]\n",
        "    predictions = list(map(lambda x: titles[x], best_k_idx))\n",
        "    return (scores, predictions)\n",
        "\n",
        "def predict_KNN_FUDNet_DR_TEIT(data, k=1):\n",
        "    inputs = tokenize_function(data, prediction=True, cuda=True)\n",
        "    outputs = fudnet_model(**inputs)\n",
        "    is_followup = bool(torch.argmax(outputs.logits))\n",
        "    \n",
        "    if is_followup:\n",
        "        dr_scores, dr_predictions = predict_DR_TEIT([data['prev_answer'], data['question'], data['history']], k=k)\n",
        "        return dr_predictions\n",
        "    else:\n",
        "        dr_scores, dr_predictions = predict_DR_TEIT([data['question']], k=k)\n",
        "        return dr_predictions"
      ],
      "metadata": {
        "id": "kQfJ4rjG135d"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit knn"
      ],
      "metadata": {
        "id": "nyjeHgyD1xRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "doc_predictor = KNeighborsClassifier(n_neighbors=100)\n",
        "doc_predictor.fit(span_embeddings, doc_ids)"
      ],
      "metadata": {
        "id": "esl3eIf010na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1771b428-7015-4570-deca-4bf8160937fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=100)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_nearests_doc_ids(\"5 DMV Mistakes\")[:5]"
      ],
      "metadata": {
        "id": "Td3uXbaV35lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3590f8-a737-4b92-b791-5dd231be6e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Top 5 DMV Mistakes and How to Avoid Them#3_0',\n",
              " 'Get a vehicle registration or title record (abstract)#1_0',\n",
              " 'In-transit vehicle permits (temporary registrations)#3_0',\n",
              " 'Exchange your out-of-state driver license#1_0',\n",
              " 'Appeal a TVB ticket conviction#1_0']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H32jwXIw5KIw"
      },
      "source": [
        "# Test\n",
        "In the test dataset we just picked ones with **user** turn."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_predictions(preds):\n",
        "    new_preds = []\n",
        "    for i in preds:\n",
        "        if i not in new_preds:\n",
        "            preds.append(i)\n",
        "    return new_preds\n",
        "\n",
        "def test_loop(df, predictor):\n",
        "    prec_at_50 = 0\n",
        "    prec_at_10 = 0\n",
        "    prec_at_5 = 0\n",
        "    prec_at_1 = 0\n",
        "    ranks = []\n",
        "    for index, data in tqdm(df.iterrows()):\n",
        "        predictions = predictor(data, k=100)\n",
        "        # print(len(predictions))\n",
        "        # predictions = merge_predictions(predictions)\n",
        "        actual_doc = data['current_doc']\n",
        "        drfud_predictions.append({\n",
        "            'domain': data['domain'],\n",
        "            'turn_id':data['turn_id'],\n",
        "            'dial_id':data['dial_id'], \n",
        "            'query': data['question'],\n",
        "            'actual_doc': actual_doc,\n",
        "            'predictions': predictions[:10]\n",
        "        })\n",
        "        # actual_domain = doc_domains[actual_doc]\n",
        "        # predictions = [p for p in predictions if doc_domains[p]==actual_domain]\n",
        "        try:\n",
        "            ranks.append(1 / (predictions.index(actual_doc) + 1))\n",
        "        except:\n",
        "            ranks.append(0)\n",
        "        if actual_doc == predictions[0]:\n",
        "            prec_at_1 += 1\n",
        "        if actual_doc in predictions[:5]:\n",
        "            prec_at_5 += 1\n",
        "        if actual_doc in predictions[:10]:\n",
        "            prec_at_10 += 1\n",
        "        if actual_doc in predictions[:50]:\n",
        "            prec_at_50 += 1\n",
        "\n",
        "        if index % 100 == 99:\n",
        "        # if index % 50 == 49:\n",
        "            print(f\"\"\"\n",
        "                MRR: mean={np.array(ranks).mean()}, var={np.array(ranks).var()}\n",
        "                Prec@(1) = {prec_at_1 / index}\n",
        "                Prec@(5) = {prec_at_5 / index}\n",
        "                Prec@(10) = {prec_at_10 / index}\n",
        "                Prec@(50) = {prec_at_50 / index}\n",
        "                NUMBER_OF_SAMPLES = {index}\n",
        "            \"\"\")\n",
        "\n",
        "    return f\"\"\"\n",
        "        MRR: mean={np.array(ranks).mean()}, var={np.array(ranks).var()}\n",
        "        Prec@(1) = {prec_at_1 / index}\n",
        "        Prec@(5) = {prec_at_5 / index}\n",
        "        Prec@(10) = {prec_at_10 / index}\n",
        "        Prec@(50) = {prec_at_50 / index}\n",
        "        NUMBER_OF_SAMPLES = {index}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "STHinF2c558c"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbiRFDJg2QP6",
        "outputId": "ca4b7cd4-4dec-4def-93f5-09aa574db91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "103it [00:04, 19.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6099460326907136, var=0.15420535612070776\n",
            "                Prec@(1) = 0.48484848484848486\n",
            "                Prec@(5) = 0.7575757575757576\n",
            "                Prec@(10) = 0.9595959595959596\n",
            "                Prec@(50) = 1.0\n",
            "                NUMBER_OF_SAMPLES = 99\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "208it [00:08, 39.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7188480863733681, var=0.13624341891854896\n",
            "                Prec@(1) = 0.6130653266331658\n",
            "                Prec@(5) = 0.8442211055276382\n",
            "                Prec@(10) = 0.9447236180904522\n",
            "                Prec@(50) = 0.9949748743718593\n",
            "                NUMBER_OF_SAMPLES = 199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "306it [00:10, 36.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.716464658314846, var=0.1327957218302478\n",
            "                Prec@(1) = 0.5986622073578596\n",
            "                Prec@(5) = 0.8494983277591973\n",
            "                Prec@(10) = 0.9364548494983278\n",
            "                Prec@(50) = 0.9866220735785953\n",
            "                NUMBER_OF_SAMPLES = 299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "408it [00:13, 39.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7245200225067268, var=0.1321743968797679\n",
            "                Prec@(1) = 0.6115288220551378\n",
            "                Prec@(5) = 0.8521303258145363\n",
            "                Prec@(10) = 0.9348370927318296\n",
            "                Prec@(50) = 0.9824561403508771\n",
            "                NUMBER_OF_SAMPLES = 399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "505it [00:15, 39.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7284368833407627, var=0.12699738393202273\n",
            "                Prec@(1) = 0.6072144288577155\n",
            "                Prec@(5) = 0.8657314629258517\n",
            "                Prec@(10) = 0.9398797595190381\n",
            "                Prec@(50) = 0.9859719438877755\n",
            "                NUMBER_OF_SAMPLES = 499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "606it [00:18, 37.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7334270326549033, var=0.12659476675871456\n",
            "                Prec@(1) = 0.6160267111853088\n",
            "                Prec@(5) = 0.8681135225375626\n",
            "                Prec@(10) = 0.9398998330550918\n",
            "                Prec@(50) = 0.986644407345576\n",
            "                NUMBER_OF_SAMPLES = 599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "705it [00:21, 38.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7259784178772282, var=0.12917638833134348\n",
            "                Prec@(1) = 0.6080114449213162\n",
            "                Prec@(5) = 0.8669527896995708\n",
            "                Prec@(10) = 0.9370529327610873\n",
            "                Prec@(50) = 0.9842632331902719\n",
            "                NUMBER_OF_SAMPLES = 699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "805it [00:24, 38.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7238244677563361, var=0.1325225780414338\n",
            "                Prec@(1) = 0.6107634543178974\n",
            "                Prec@(5) = 0.8585732165206508\n",
            "                Prec@(10) = 0.9311639549436797\n",
            "                Prec@(50) = 0.9799749687108886\n",
            "                NUMBER_OF_SAMPLES = 799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "906it [00:26, 38.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7233664294738673, var=0.1341296118753345\n",
            "                Prec@(1) = 0.6129032258064516\n",
            "                Prec@(5) = 0.8565072302558399\n",
            "                Prec@(10) = 0.9254727474972191\n",
            "                Prec@(50) = 0.9766407119021134\n",
            "                NUMBER_OF_SAMPLES = 899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1007it [00:29, 38.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7212364637271474, var=0.1345491578923929\n",
            "                Prec@(1) = 0.6096096096096096\n",
            "                Prec@(5) = 0.8578578578578578\n",
            "                Prec@(10) = 0.923923923923924\n",
            "                Prec@(50) = 0.973973973973974\n",
            "                NUMBER_OF_SAMPLES = 999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1107it [00:32, 37.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7217546416634442, var=0.1370111041657466\n",
            "                Prec@(1) = 0.6151046405823476\n",
            "                Prec@(5) = 0.8516833484986351\n",
            "                Prec@(10) = 0.916287534121929\n",
            "                Prec@(50) = 0.9717925386715196\n",
            "                NUMBER_OF_SAMPLES = 1099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1206it [00:34, 37.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7141569229054331, var=0.13795535184765204\n",
            "                Prec@(1) = 0.603836530442035\n",
            "                Prec@(5) = 0.8523769808173478\n",
            "                Prec@(10) = 0.9149291075896581\n",
            "                Prec@(50) = 0.9724770642201835\n",
            "                NUMBER_OF_SAMPLES = 1199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1305it [00:37, 36.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7196545160770415, var=0.13860429291243762\n",
            "                Prec@(1) = 0.6143187066974596\n",
            "                Prec@(5) = 0.850654349499615\n",
            "                Prec@(10) = 0.9099307159353349\n",
            "                Prec@(50) = 0.9668976135488837\n",
            "                NUMBER_OF_SAMPLES = 1299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1405it [00:39, 40.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.703476467280082, var=0.14217000508613084\n",
            "                Prec@(1) = 0.5932809149392423\n",
            "                Prec@(5) = 0.8456040028591851\n",
            "                Prec@(10) = 0.9027877055039314\n",
            "                Prec@(50) = 0.9649749821300929\n",
            "                NUMBER_OF_SAMPLES = 1399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1507it [00:42, 38.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6935380371099688, var=0.14416348942486096\n",
            "                Prec@(1) = 0.5810540360240161\n",
            "                Prec@(5) = 0.8418945963975984\n",
            "                Prec@(10) = 0.9026017344896597\n",
            "                Prec@(50) = 0.961974649766511\n",
            "                NUMBER_OF_SAMPLES = 1499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1604it [00:45, 39.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6988422575654198, var=0.14262446954494593\n",
            "                Prec@(1) = 0.5866166353971232\n",
            "                Prec@(5) = 0.8449030644152595\n",
            "                Prec@(10) = 0.9030644152595372\n",
            "                Prec@(50) = 0.9631019387116948\n",
            "                NUMBER_OF_SAMPLES = 1599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1707it [00:47, 37.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7030553112105774, var=0.14284821194580732\n",
            "                Prec@(1) = 0.5938787522071807\n",
            "                Prec@(5) = 0.8428487345497352\n",
            "                Prec@(10) = 0.901706886403767\n",
            "                Prec@(50) = 0.9599764567392584\n",
            "                NUMBER_OF_SAMPLES = 1699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1805it [00:50, 35.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.7016355977846782, var=0.14362495531267536\n",
            "                Prec@(1) = 0.5925514174541412\n",
            "                Prec@(5) = 0.839355197331851\n",
            "                Prec@(10) = 0.8977209560867149\n",
            "                Prec@(50) = 0.9599777654252363\n",
            "                NUMBER_OF_SAMPLES = 1799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1905it [00:53, 40.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6998671697189301, var=0.14446047298782763\n",
            "                Prec@(1) = 0.5913638757240653\n",
            "                Prec@(5) = 0.8378093733543971\n",
            "                Prec@(10) = 0.8967877830437072\n",
            "                Prec@(50) = 0.9594523433385993\n",
            "                NUMBER_OF_SAMPLES = 1899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2005it [00:55, 37.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6985871903784078, var=0.14435069334898093\n",
            "                Prec@(1) = 0.5887943971985993\n",
            "                Prec@(5) = 0.8379189594797398\n",
            "                Prec@(10) = 0.8959479739869936\n",
            "                Prec@(50) = 0.959479739869935\n",
            "                NUMBER_OF_SAMPLES = 1999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2104it [00:58, 34.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6945312645123757, var=0.14455184367912183\n",
            "                Prec@(1) = 0.5821819914244879\n",
            "                Prec@(5) = 0.837065269175798\n",
            "                Prec@(10) = 0.8947117675083373\n",
            "                Prec@(50) = 0.9590281086231539\n",
            "                NUMBER_OF_SAMPLES = 2099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2206it [01:01, 36.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6921398285681184, var=0.14505442631530047\n",
            "                Prec@(1) = 0.5793542519326966\n",
            "                Prec@(5) = 0.8353797180536607\n",
            "                Prec@(10) = 0.8949522510231923\n",
            "                Prec@(50) = 0.9595270577535243\n",
            "                NUMBER_OF_SAMPLES = 2199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2305it [01:03, 37.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.686668129803294, var=0.14609524559400622\n",
            "                Prec@(1) = 0.5724227925184863\n",
            "                Prec@(5) = 0.8321009134406263\n",
            "                Prec@(10) = 0.8929969551979121\n",
            "                Prec@(50) = 0.9582427142235754\n",
            "                NUMBER_OF_SAMPLES = 2299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2406it [01:06, 30.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6833540807440298, var=0.14603907775276867\n",
            "                Prec@(1) = 0.5664860358482701\n",
            "                Prec@(5) = 0.8315964985410588\n",
            "                Prec@(10) = 0.8924551896623594\n",
            "                Prec@(50) = 0.9558149228845352\n",
            "                NUMBER_OF_SAMPLES = 2399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2501it [01:09, 28.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6884876317842696, var=0.14579016223784913\n",
            "                Prec@(1) = 0.5746298519407763\n",
            "                Prec@(5) = 0.8331332533013205\n",
            "                Prec@(10) = 0.8935574229691877\n",
            "                Prec@(50) = 0.9559823929571829\n",
            "                NUMBER_OF_SAMPLES = 2499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2604it [01:13, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6906543964765879, var=0.14579306254606314\n",
            "                Prec@(1) = 0.5782993459022701\n",
            "                Prec@(5) = 0.8337822239322816\n",
            "                Prec@(10) = 0.893035782993459\n",
            "                Prec@(50) = 0.9545979222777992\n",
            "                NUMBER_OF_SAMPLES = 2599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2706it [01:16, 38.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.690262972051894, var=0.14539041536797262\n",
            "                Prec@(1) = 0.5768803260466839\n",
            "                Prec@(5) = 0.8347536124490552\n",
            "                Prec@(10) = 0.8947758429047795\n",
            "                Prec@(50) = 0.9547980733605039\n",
            "                NUMBER_OF_SAMPLES = 2699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2803it [01:19, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6873272352310005, var=0.14527674945643704\n",
            "                Prec@(1) = 0.5719899964272954\n",
            "                Prec@(5) = 0.8342265094676671\n",
            "                Prec@(10) = 0.8960342979635584\n",
            "                Prec@(50) = 0.9556984637370489\n",
            "                NUMBER_OF_SAMPLES = 2799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2904it [01:22, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6911168916963892, var=0.14397566760494362\n",
            "                Prec@(1) = 0.5757157640565712\n",
            "                Prec@(5) = 0.8385650224215246\n",
            "                Prec@(10) = 0.8982407726802346\n",
            "                Prec@(50) = 0.9565367368057951\n",
            "                NUMBER_OF_SAMPLES = 2899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3004it [01:24, 36.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6894679106853917, var=0.14432356936583118\n",
            "                Prec@(1) = 0.5735245081693898\n",
            "                Prec@(5) = 0.8372790930310103\n",
            "                Prec@(10) = 0.8972990996999\n",
            "                Prec@(50) = 0.9559853284428143\n",
            "                NUMBER_OF_SAMPLES = 2999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3108it [01:27, 38.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6846279640431638, var=0.14551326973909137\n",
            "                Prec@(1) = 0.5676024524040013\n",
            "                Prec@(5) = 0.8338173604388512\n",
            "                Prec@(10) = 0.8944820909970959\n",
            "                Prec@(50) = 0.9535333978702807\n",
            "                NUMBER_OF_SAMPLES = 3099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3203it [01:30, 35.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6787710431756118, var=0.14621528575908724\n",
            "                Prec@(1) = 0.5598624570178181\n",
            "                Prec@(5) = 0.8336980306345733\n",
            "                Prec@(10) = 0.8946545795561113\n",
            "                Prec@(50) = 0.9537355423569865\n",
            "                NUMBER_OF_SAMPLES = 3199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3303it [01:33, 28.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6782031328492297, var=0.146347188873552\n",
            "                Prec@(1) = 0.5592603819339194\n",
            "                Prec@(5) = 0.8338890572900879\n",
            "                Prec@(10) = 0.8945134889360412\n",
            "                Prec@(50) = 0.9533191876326159\n",
            "                NUMBER_OF_SAMPLES = 3299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3403it [01:37, 22.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.67835570629164, var=0.14667932446894894\n",
            "                Prec@(1) = 0.5601647543395116\n",
            "                Prec@(5) = 0.8331862312444837\n",
            "                Prec@(10) = 0.8932038834951457\n",
            "                Prec@(50) = 0.9532215357458076\n",
            "                NUMBER_OF_SAMPLES = 3399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3507it [01:40, 36.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6732474110781711, var=0.1474242161186695\n",
            "                Prec@(1) = 0.5533009431266076\n",
            "                Prec@(5) = 0.830237210631609\n",
            "                Prec@(10) = 0.8905401543298085\n",
            "                Prec@(50) = 0.9525578736781938\n",
            "                NUMBER_OF_SAMPLES = 3499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3607it [01:43, 37.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6700267771627351, var=0.14728774471046202\n",
            "                Prec@(1) = 0.5476521255904417\n",
            "                Prec@(5) = 0.8293970547374271\n",
            "                Prec@(10) = 0.8896915809947208\n",
            "                Prec@(50) = 0.9519310919699917\n",
            "                NUMBER_OF_SAMPLES = 3599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3704it [01:45, 37.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6687201012765858, var=0.14808429648196034\n",
            "                Prec@(1) = 0.5471749121384157\n",
            "                Prec@(5) = 0.8275209516085429\n",
            "                Prec@(10) = 0.8872668288726683\n",
            "                Prec@(50) = 0.9513381995133819\n",
            "                NUMBER_OF_SAMPLES = 3699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3806it [01:48, 35.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.670021014768276, var=0.14802146953721568\n",
            "                Prec@(1) = 0.5490918662806001\n",
            "                Prec@(5) = 0.8278494340615952\n",
            "                Prec@(10) = 0.8873387733614109\n",
            "                Prec@(50) = 0.9515662016320084\n",
            "                NUMBER_OF_SAMPLES = 3799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3904it [01:51, 36.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6640935743607752, var=0.1498512092113975\n",
            "                Prec@(1) = 0.5432162092844319\n",
            "                Prec@(5) = 0.8214926904334445\n",
            "                Prec@(10) = 0.8825339830725827\n",
            "                Prec@(50) = 0.9499871761990254\n",
            "                NUMBER_OF_SAMPLES = 3899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4005it [01:54, 37.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6657180353822209, var=0.1492319179927113\n",
            "                Prec@(1) = 0.5443860965241311\n",
            "                Prec@(5) = 0.8232058014503626\n",
            "                Prec@(10) = 0.8834708677169293\n",
            "                Prec@(50) = 0.9497374343585896\n",
            "                NUMBER_OF_SAMPLES = 3999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4105it [01:56, 37.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6646468777265256, var=0.14923592773277178\n",
            "                Prec@(1) = 0.5428153208099536\n",
            "                Prec@(5) = 0.8231275920956331\n",
            "                Prec@(10) = 0.8838741156379605\n",
            "                Prec@(50) = 0.9499878019029031\n",
            "                NUMBER_OF_SAMPLES = 4099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4207it [01:59, 35.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6657266573582937, var=0.14940598194100752\n",
            "                Prec@(1) = 0.544891640866873\n",
            "                Prec@(5) = 0.8228149559418909\n",
            "                Prec@(10) = 0.8837818528221005\n",
            "                Prec@(50) = 0.9504643962848297\n",
            "                NUMBER_OF_SAMPLES = 4199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4306it [02:02, 37.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6666935154453585, var=0.14988116044353372\n",
            "                Prec@(1) = 0.547336589904629\n",
            "                Prec@(5) = 0.8213538032100488\n",
            "                Prec@(10) = 0.8827634333565946\n",
            "                Prec@(50) = 0.9506862060944405\n",
            "                NUMBER_OF_SAMPLES = 4299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4407it [02:05, 37.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6667794634206565, var=0.15012857545298877\n",
            "                Prec@(1) = 0.5478517844964764\n",
            "                Prec@(5) = 0.8204137303932711\n",
            "                Prec@(10) = 0.8817913162082291\n",
            "                Prec@(50) = 0.9506706069561264\n",
            "                NUMBER_OF_SAMPLES = 4399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4504it [02:07, 37.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6698429571212299, var=0.15005532689910353\n",
            "                Prec@(1) = 0.5525672371638142\n",
            "                Prec@(5) = 0.8210713491887086\n",
            "                Prec@(10) = 0.8821960435652367\n",
            "                Prec@(50) = 0.9508779728828629\n",
            "                NUMBER_OF_SAMPLES = 4499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4606it [02:10, 39.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6697996726234308, var=0.14991718447168403\n",
            "                Prec@(1) = 0.5520765383779083\n",
            "                Prec@(5) = 0.8203957382039574\n",
            "                Prec@(10) = 0.8823657316808001\n",
            "                Prec@(50) = 0.9508588823657317\n",
            "                NUMBER_OF_SAMPLES = 4599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4704it [02:13, 36.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.667912351046899, var=0.14992674593494873\n",
            "                Prec@(1) = 0.5492658012343051\n",
            "                Prec@(5) = 0.8201745052138752\n",
            "                Prec@(10) = 0.8825281974888274\n",
            "                Prec@(50) = 0.9516918493296446\n",
            "                NUMBER_OF_SAMPLES = 4699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4804it [02:15, 36.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6653532155659498, var=0.15028544392063992\n",
            "                Prec@(1) = 0.5461554490518858\n",
            "                Prec@(5) = 0.8182954782246301\n",
            "                Prec@(10) = 0.8824755157324442\n",
            "                Prec@(50) = 0.9518649718691394\n",
            "                NUMBER_OF_SAMPLES = 4799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4906it [02:18, 35.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.666724133389858, var=0.15027255196920378\n",
            "                Prec@(1) = 0.5482751581955501\n",
            "                Prec@(5) = 0.8189426413553786\n",
            "                Prec@(10) = 0.8824249846907533\n",
            "                Prec@(50) = 0.9512145335782812\n",
            "                NUMBER_OF_SAMPLES = 4899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5007it [02:21, 38.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6678916430493164, var=0.1498770531483266\n",
            "                Prec@(1) = 0.5495099019803961\n",
            "                Prec@(5) = 0.8209641928385677\n",
            "                Prec@(10) = 0.8837767553510703\n",
            "                Prec@(50) = 0.9517903580716143\n",
            "                NUMBER_OF_SAMPLES = 4999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5107it [02:24, 34.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6646546902226226, var=0.1494006112215821\n",
            "                Prec@(1) = 0.5432437732888802\n",
            "                Prec@(5) = 0.8211414002745636\n",
            "                Prec@(10) = 0.8842910374583252\n",
            "                Prec@(50) = 0.9519513630123554\n",
            "                NUMBER_OF_SAMPLES = 5099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5204it [02:26, 36.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6623872849531345, var=0.1500201216689935\n",
            "                Prec@(1) = 0.5408732448547797\n",
            "                Prec@(5) = 0.8197730332756299\n",
            "                Prec@(10) = 0.8822850548182343\n",
            "                Prec@(50) = 0.950182727447586\n",
            "                NUMBER_OF_SAMPLES = 5199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5306it [02:29, 37.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6623222707560446, var=0.15078484086096136\n",
            "                Prec@(1) = 0.542177769390451\n",
            "                Prec@(5) = 0.8178901679562182\n",
            "                Prec@(10) = 0.8801660690696358\n",
            "                Prec@(50) = 0.9484808454425363\n",
            "                NUMBER_OF_SAMPLES = 5299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5407it [02:32, 38.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6628138343031544, var=0.15037723872185477\n",
            "                Prec@(1) = 0.5421374328579367\n",
            "                Prec@(5) = 0.8190405630672347\n",
            "                Prec@(10) = 0.8805334321170587\n",
            "                Prec@(50) = 0.9492498610853862\n",
            "                NUMBER_OF_SAMPLES = 5399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5504it [02:34, 38.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6647817685221187, var=0.1498894250757893\n",
            "                Prec@(1) = 0.5442807783233315\n",
            "                Prec@(5) = 0.8210583742498636\n",
            "                Prec@(10) = 0.8816148390616476\n",
            "                Prec@(50) = 0.9496272049463539\n",
            "                NUMBER_OF_SAMPLES = 5499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5607it [02:37, 39.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.664168627087721, var=0.1498566626741603\n",
            "                Prec@(1) = 0.543311305590284\n",
            "                Prec@(5) = 0.821753884622254\n",
            "                Prec@(10) = 0.8821218074656189\n",
            "                Prec@(50) = 0.9496338631898553\n",
            "                NUMBER_OF_SAMPLES = 5599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5703it [02:40, 36.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6623438112602119, var=0.15001453401107903\n",
            "                Prec@(1) = 0.5407966309878927\n",
            "                Prec@(5) = 0.8208457624144587\n",
            "                Prec@(10) = 0.8820845762414459\n",
            "                Prec@(50) = 0.949289349008598\n",
            "                NUMBER_OF_SAMPLES = 5699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5808it [02:42, 41.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6613961705374944, var=0.15044460172700136\n",
            "                Prec@(1) = 0.5402655630281082\n",
            "                Prec@(5) = 0.8192791860665632\n",
            "                Prec@(10) = 0.88118641145025\n",
            "                Prec@(50) = 0.9498189342990171\n",
            "                NUMBER_OF_SAMPLES = 5799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5904it [02:45, 36.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6629652089728638, var=0.15049004013707032\n",
            "                Prec@(1) = 0.542803865061875\n",
            "                Prec@(5) = 0.8194609255806069\n",
            "                Prec@(10) = 0.8815053398881166\n",
            "                Prec@(50) = 0.9498220037294457\n",
            "                NUMBER_OF_SAMPLES = 5899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6006it [02:48, 38.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6651603519989319, var=0.1502689125134361\n",
            "                Prec@(1) = 0.5457576262710452\n",
            "                Prec@(5) = 0.8208034672445408\n",
            "                Prec@(10) = 0.8819803300550092\n",
            "                Prec@(50) = 0.9496582763793966\n",
            "                NUMBER_OF_SAMPLES = 5999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6105it [02:51, 38.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6660721512623408, var=0.1497646747056761\n",
            "                Prec@(1) = 0.5461551073946549\n",
            "                Prec@(5) = 0.8221019839317921\n",
            "                Prec@(10) = 0.883095589440892\n",
            "                Prec@(50) = 0.9503197245450073\n",
            "                NUMBER_OF_SAMPLES = 6099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6204it [02:53, 38.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6665446892815029, var=0.14980928791499995\n",
            "                Prec@(1) = 0.5470237135021778\n",
            "                Prec@(5) = 0.8215841264720116\n",
            "                Prec@(10) = 0.8832069688659461\n",
            "                Prec@(50) = 0.9506371995483143\n",
            "                NUMBER_OF_SAMPLES = 6199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6307it [02:56, 37.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6642425796440355, var=0.15021647750153116\n",
            "                Prec@(1) = 0.5440546118431497\n",
            "                Prec@(5) = 0.8194951579615812\n",
            "                Prec@(10) = 0.8810922368629941\n",
            "                Prec@(50) = 0.9501508175900937\n",
            "                NUMBER_OF_SAMPLES = 6299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6404it [02:59, 38.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6635536991985319, var=0.14994249075941352\n",
            "                Prec@(1) = 0.542428504453821\n",
            "                Prec@(5) = 0.8201281450226597\n",
            "                Prec@(10) = 0.8813877168307548\n",
            "                Prec@(50) = 0.9504610095327395\n",
            "                NUMBER_OF_SAMPLES = 6399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6507it [03:01, 36.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.663495913487078, var=0.15051913084858443\n",
            "                Prec@(1) = 0.5433143560547776\n",
            "                Prec@(5) = 0.8182797353438991\n",
            "                Prec@(10) = 0.8795199261424834\n",
            "                Prec@(50) = 0.9492229573780582\n",
            "                NUMBER_OF_SAMPLES = 6499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6605it [03:04, 37.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6581472171325893, var=0.15211440148272565\n",
            "                Prec@(1) = 0.5381118351265344\n",
            "                Prec@(5) = 0.8125473556599485\n",
            "                Prec@(10) = 0.8757387482951963\n",
            "                Prec@(50) = 0.9474162751932111\n",
            "                NUMBER_OF_SAMPLES = 6599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6707it [03:06, 39.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6552341398648998, var=0.15232909276315434\n",
            "                Prec@(1) = 0.5341095685923272\n",
            "                Prec@(5) = 0.8107180176145693\n",
            "                Prec@(10) = 0.8756530825496343\n",
            "                Prec@(50) = 0.9474548440065681\n",
            "                NUMBER_OF_SAMPLES = 6699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6806it [03:09, 35.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6502852282925644, var=0.15343211762747253\n",
            "                Prec@(1) = 0.528754228563024\n",
            "                Prec@(5) = 0.8055596411236947\n",
            "                Prec@(10) = 0.8721870863362259\n",
            "                Prec@(50) = 0.9476393587292249\n",
            "                NUMBER_OF_SAMPLES = 6799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6908it [03:12, 39.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6439737685979233, var=0.15478018267348953\n",
            "                Prec@(1) = 0.5219597043049717\n",
            "                Prec@(5) = 0.7992462675750108\n",
            "                Prec@(10) = 0.8670821858240325\n",
            "                Prec@(50) = 0.9479634729670967\n",
            "                NUMBER_OF_SAMPLES = 6899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7004it [03:15, 38.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6396705846407144, var=0.15589812494786792\n",
            "                Prec@(1) = 0.5177882554650665\n",
            "                Prec@(5) = 0.7939705672238891\n",
            "                Prec@(10) = 0.8628375482211744\n",
            "                Prec@(50) = 0.9482783254750679\n",
            "                NUMBER_OF_SAMPLES = 6999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7104it [03:17, 37.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6349755934949645, var=0.1568223567083446\n",
            "                Prec@(1) = 0.5127482744048457\n",
            "                Prec@(5) = 0.7891252289054796\n",
            "                Prec@(10) = 0.8598394140019721\n",
            "                Prec@(50) = 0.9484434427384139\n",
            "                NUMBER_OF_SAMPLES = 7099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7205it [03:20, 38.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6306750617991386, var=0.15749590892284535\n",
            "                Prec@(1) = 0.5079872204472844\n",
            "                Prec@(5) = 0.7863592165578552\n",
            "                Prec@(10) = 0.8577580219474927\n",
            "                Prec@(50) = 0.947770523683845\n",
            "                NUMBER_OF_SAMPLES = 7199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7306it [03:23, 36.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6282029281250501, var=0.15780290359009888\n",
            "                Prec@(1) = 0.5051376900945335\n",
            "                Prec@(5) = 0.7846280312371557\n",
            "                Prec@(10) = 0.8566926976298123\n",
            "                Prec@(50) = 0.9480750787779147\n",
            "                NUMBER_OF_SAMPLES = 7299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7406it [03:26, 36.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6260881335961954, var=0.15815146438727934\n",
            "                Prec@(1) = 0.5029057980808217\n",
            "                Prec@(5) = 0.782538180835248\n",
            "                Prec@(10) = 0.8556561697526692\n",
            "                Prec@(50) = 0.9482362481416408\n",
            "                NUMBER_OF_SAMPLES = 7399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7507it [03:28, 35.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6227431712589444, var=0.15835459306260521\n",
            "                Prec@(1) = 0.4985998133084411\n",
            "                Prec@(5) = 0.7801040138685158\n",
            "                Prec@(10) = 0.8543805840778771\n",
            "                Prec@(50) = 0.9485264701960261\n",
            "                NUMBER_OF_SAMPLES = 7499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7607it [03:31, 36.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6197502919375139, var=0.15859605976726435\n",
            "                Prec@(1) = 0.4949335438873536\n",
            "                Prec@(5) = 0.7778655086195552\n",
            "                Prec@(10) = 0.8528753783392552\n",
            "                Prec@(50) = 0.9489406500855375\n",
            "                NUMBER_OF_SAMPLES = 7599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7704it [03:34, 36.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6154386530201585, var=0.15918464685153308\n",
            "                Prec@(1) = 0.4900636446291726\n",
            "                Prec@(5) = 0.7737368489414209\n",
            "                Prec@(10) = 0.8499805169502532\n",
            "                Prec@(50) = 0.9490842966619042\n",
            "                NUMBER_OF_SAMPLES = 7699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7805it [03:37, 37.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6115225200978381, var=0.1597787171448046\n",
            "                Prec@(1) = 0.48583151686113607\n",
            "                Prec@(5) = 0.7694576227721502\n",
            "                Prec@(10) = 0.8469034491601487\n",
            "                Prec@(50) = 0.9489678163867162\n",
            "                NUMBER_OF_SAMPLES = 7799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7906it [03:39, 37.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6078599708186698, var=0.1601639866985147\n",
            "                Prec@(1) = 0.48157994682871247\n",
            "                Prec@(5) = 0.766172933282694\n",
            "                Prec@(10) = 0.8441574882896569\n",
            "                Prec@(50) = 0.9487276870489936\n",
            "                NUMBER_OF_SAMPLES = 7899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8006it [03:42, 40.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6039767114825632, var=0.16063618278649325\n",
            "                Prec@(1) = 0.4773096637079635\n",
            "                Prec@(5) = 0.7622202775346918\n",
            "                Prec@(10) = 0.8419802475309414\n",
            "                Prec@(50) = 0.9487435929491186\n",
            "                NUMBER_OF_SAMPLES = 7999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8107it [03:45, 40.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6005367852796513, var=0.16089470182884177\n",
            "                Prec@(1) = 0.4733917767625633\n",
            "                Prec@(5) = 0.7592295345104334\n",
            "                Prec@(10) = 0.8407210766761328\n",
            "                Prec@(50) = 0.9488825780960612\n",
            "                NUMBER_OF_SAMPLES = 8099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8206it [03:47, 37.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.599172400354893, var=0.1606541250864164\n",
            "                Prec@(1) = 0.4711550189047445\n",
            "                Prec@(5) = 0.7588730332967435\n",
            "                Prec@(10) = 0.8410781802658861\n",
            "                Prec@(50) = 0.9492621051347725\n",
            "                NUMBER_OF_SAMPLES = 8199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8305it [03:50, 37.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5955343930514322, var=0.16076219251663543\n",
            "                Prec@(1) = 0.4665622364140258\n",
            "                Prec@(5) = 0.7557537052656946\n",
            "                Prec@(10) = 0.8388962525605494\n",
            "                Prec@(50) = 0.9498734787323774\n",
            "                NUMBER_OF_SAMPLES = 8299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8406it [03:53, 35.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5929772195401778, var=0.1606944277234986\n",
            "                Prec@(1) = 0.4630313132515776\n",
            "                Prec@(5) = 0.7544945826884153\n",
            "                Prec@(10) = 0.8375997142516967\n",
            "                Prec@(50) = 0.9493987379449934\n",
            "                NUMBER_OF_SAMPLES = 8399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8504it [03:55, 37.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5904825476751515, var=0.1606850918998763\n",
            "                Prec@(1) = 0.45993646311330744\n",
            "                Prec@(5) = 0.752912107306742\n",
            "                Prec@(10) = 0.8369219908224497\n",
            "                Prec@(50) = 0.9497587951523708\n",
            "                NUMBER_OF_SAMPLES = 8499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8605it [03:58, 38.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5891420929772503, var=0.16096000958094028\n",
            "                Prec@(1) = 0.4587742760786138\n",
            "                Prec@(5) = 0.7510175601814164\n",
            "                Prec@(10) = 0.836260030236074\n",
            "                Prec@(50) = 0.9494127224095825\n",
            "                NUMBER_OF_SAMPLES = 8599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8703it [04:01, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5851269964611236, var=0.16144566511834896\n",
            "                Prec@(1) = 0.454535004023451\n",
            "                Prec@(5) = 0.7464076330612714\n",
            "                Prec@(10) = 0.8321646166226003\n",
            "                Prec@(50) = 0.9495344292447407\n",
            "                NUMBER_OF_SAMPLES = 8699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8805it [04:03, 39.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5824175147786346, var=0.16139991399292664\n",
            "                Prec@(1) = 0.45096033640186384\n",
            "                Prec@(5) = 0.7442891237640641\n",
            "                Prec@(10) = 0.8302079781793386\n",
            "                Prec@(50) = 0.9499943175360837\n",
            "                NUMBER_OF_SAMPLES = 8799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8905it [04:06, 39.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5813018551482668, var=0.16132347598043906\n",
            "                Prec@(1) = 0.44937633441959773\n",
            "                Prec@(5) = 0.7433419485335431\n",
            "                Prec@(10) = 0.8297561523766716\n",
            "                Prec@(50) = 0.9501067535678166\n",
            "                NUMBER_OF_SAMPLES = 8899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9007it [04:08, 39.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5786911943754305, var=0.16141164869063634\n",
            "                Prec@(1) = 0.4462718079786643\n",
            "                Prec@(5) = 0.740748972108012\n",
            "                Prec@(10) = 0.8284253805978442\n",
            "                Prec@(50) = 0.9496610734526059\n",
            "                NUMBER_OF_SAMPLES = 8999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9105it [04:11, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5768004637587584, var=0.16148632746495337\n",
            "                Prec@(1) = 0.44411473788328387\n",
            "                Prec@(5) = 0.7392021101219914\n",
            "                Prec@(10) = 0.8272337619518628\n",
            "                Prec@(50) = 0.9494449939553797\n",
            "                NUMBER_OF_SAMPLES = 9099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9206it [04:14, 36.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5742205973980913, var=0.16159076690271854\n",
            "                Prec@(1) = 0.44102619849983693\n",
            "                Prec@(5) = 0.7370366344167845\n",
            "                Prec@(10) = 0.8250896836612676\n",
            "                Prec@(50) = 0.9492336123491684\n",
            "                NUMBER_OF_SAMPLES = 9199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9306it [04:16, 39.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5719921927499341, var=0.16168396430417542\n",
            "                Prec@(1) = 0.4385417786858802\n",
            "                Prec@(5) = 0.7353478868695559\n",
            "                Prec@(10) = 0.8234218733197118\n",
            "                Prec@(50) = 0.9491343155177976\n",
            "                NUMBER_OF_SAMPLES = 9299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9405it [04:19, 37.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5703988369833489, var=0.16166617706566003\n",
            "                Prec@(1) = 0.43664219597829557\n",
            "                Prec@(5) = 0.7340142568358335\n",
            "                Prec@(10) = 0.8230662836471965\n",
            "                Prec@(50) = 0.9490371316097457\n",
            "                NUMBER_OF_SAMPLES = 9399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9506it [04:22, 38.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5687175173666615, var=0.1616347679030933\n",
            "                Prec@(1) = 0.43457206021686495\n",
            "                Prec@(5) = 0.7328139804189915\n",
            "                Prec@(10) = 0.8221918096641752\n",
            "                Prec@(50) = 0.9491525423728814\n",
            "                NUMBER_OF_SAMPLES = 9499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9604it [04:25, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.567408415135457, var=0.1618415869445344\n",
            "                Prec@(1) = 0.4333784769246797\n",
            "                Prec@(5) = 0.7309094697364309\n",
            "                Prec@(10) = 0.8207104906761121\n",
            "                Prec@(50) = 0.9490571934576518\n",
            "                NUMBER_OF_SAMPLES = 9599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9704it [04:29, 25.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5663293157031167, var=0.16151264827418044\n",
            "                Prec@(1) = 0.43138467883286935\n",
            "                Prec@(5) = 0.7303845757294567\n",
            "                Prec@(10) = 0.8204969584493247\n",
            "                Prec@(50) = 0.949376224353026\n",
            "                NUMBER_OF_SAMPLES = 9699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9804it [04:32, 36.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5654477911579959, var=0.16099660095790985\n",
            "                Prec@(1) = 0.4292274721910399\n",
            "                Prec@(5) = 0.7308909072354322\n",
            "                Prec@(10) = 0.8209000918461068\n",
            "                Prec@(50) = 0.9495866925196449\n",
            "                NUMBER_OF_SAMPLES = 9799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9907it [04:35, 36.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5652640744753459, var=0.16073492647286433\n",
            "                Prec@(1) = 0.4284271138498838\n",
            "                Prec@(5) = 0.7313870087887665\n",
            "                Prec@(10) = 0.8213961006162238\n",
            "                Prec@(50) = 0.9494898474593393\n",
            "                NUMBER_OF_SAMPLES = 9899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10004it [04:37, 38.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5639679066094507, var=0.1608187431522672\n",
            "                Prec@(1) = 0.42704270427042706\n",
            "                Prec@(5) = 0.7300730073007301\n",
            "                Prec@(10) = 0.8204820482048205\n",
            "                Prec@(50) = 0.9491949194919492\n",
            "                NUMBER_OF_SAMPLES = 9999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10106it [04:40, 37.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5631834352725824, var=0.16055500900197275\n",
            "                Prec@(1) = 0.4255866917516586\n",
            "                Prec@(5) = 0.7303693434993563\n",
            "                Prec@(10) = 0.8205762946826418\n",
            "                Prec@(50) = 0.9491038716704624\n",
            "                NUMBER_OF_SAMPLES = 10099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10207it [04:43, 37.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5614465207462469, var=0.1604787158498672\n",
            "                Prec@(1) = 0.423374840670654\n",
            "                Prec@(5) = 0.7289930385331895\n",
            "                Prec@(10) = 0.8194921070693205\n",
            "                Prec@(50) = 0.9493087557603687\n",
            "                NUMBER_OF_SAMPLES = 10199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10305it [04:45, 37.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.559394621451361, var=0.1603685778985276\n",
            "                Prec@(1) = 0.4208175551024371\n",
            "                Prec@(5) = 0.7277405573356637\n",
            "                Prec@(10) = 0.8183318768812506\n",
            "                Prec@(50) = 0.9491212739100884\n",
            "                NUMBER_OF_SAMPLES = 10299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10405it [04:48, 38.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5574624819429091, var=0.16027159486074172\n",
            "                Prec@(1) = 0.4184056159246081\n",
            "                Prec@(5) = 0.7259351860755842\n",
            "                Prec@(10) = 0.8175786133282046\n",
            "                Prec@(50) = 0.9495143763823445\n",
            "                NUMBER_OF_SAMPLES = 10399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10506it [04:51, 37.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5558374604458998, var=0.1601241533798103\n",
            "                Prec@(1) = 0.41623011715401464\n",
            "                Prec@(5) = 0.7249261834460424\n",
            "                Prec@(10) = 0.8167444518525574\n",
            "                Prec@(50) = 0.9493285074769026\n",
            "                NUMBER_OF_SAMPLES = 10499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10606it [04:53, 35.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5563388763670227, var=0.15980417410650355\n",
            "                Prec@(1) = 0.41607698839513163\n",
            "                Prec@(5) = 0.7261062364373998\n",
            "                Prec@(10) = 0.8174356071327483\n",
            "                Prec@(50) = 0.9492404943862629\n",
            "                NUMBER_OF_SAMPLES = 10599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10704it [04:56, 36.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5547951248825157, var=0.15971571568922216\n",
            "                Prec@(1) = 0.414150855220114\n",
            "                Prec@(5) = 0.7251144966819328\n",
            "                Prec@(10) = 0.8165249088699879\n",
            "                Prec@(50) = 0.9490606598747546\n",
            "                NUMBER_OF_SAMPLES = 10699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10807it [04:59, 38.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5544019418968635, var=0.15953629792585197\n",
            "                Prec@(1) = 0.41327900731549216\n",
            "                Prec@(5) = 0.7250671358459116\n",
            "                Prec@(10) = 0.8163718862857672\n",
            "                Prec@(50) = 0.9491619594406889\n",
            "                NUMBER_OF_SAMPLES = 10799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10907it [05:02, 37.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5528685411633467, var=0.15977360764185528\n",
            "                Prec@(1) = 0.41196440040370674\n",
            "                Prec@(5) = 0.7229103587485091\n",
            "                Prec@(10) = 0.8147536471235893\n",
            "                Prec@(50) = 0.9488943939810992\n",
            "                NUMBER_OF_SAMPLES = 10899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11006it [05:04, 38.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.550804989596744, var=0.1595280319269506\n",
            "                Prec@(1) = 0.4091281025547777\n",
            "                Prec@(5) = 0.7217928902627512\n",
            "                Prec@(10) = 0.8138921720156378\n",
            "                Prec@(50) = 0.9487226111464678\n",
            "                NUMBER_OF_SAMPLES = 10999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11108it [05:07, 40.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.550695953004222, var=0.15914427920829752\n",
            "                Prec@(1) = 0.40814487791692944\n",
            "                Prec@(5) = 0.7224074240922606\n",
            "                Prec@(10) = 0.814307595278854\n",
            "                Prec@(50) = 0.9489143166050995\n",
            "                NUMBER_OF_SAMPLES = 11099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11204it [05:09, 37.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5500095654347662, var=0.1589532788847596\n",
            "                Prec@(1) = 0.40708991874274486\n",
            "                Prec@(5) = 0.7228323957496205\n",
            "                Prec@(10) = 0.8144477185462988\n",
            "                Prec@(50) = 0.9491025984462899\n",
            "                NUMBER_OF_SAMPLES = 11199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11306it [05:12, 39.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5507661634483149, var=0.15897506669972397\n",
            "                Prec@(1) = 0.4080007080272591\n",
            "                Prec@(5) = 0.7235153553411806\n",
            "                Prec@(10) = 0.815027878573325\n",
            "                Prec@(50) = 0.9491990441632003\n",
            "                NUMBER_OF_SAMPLES = 11299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11404it [05:15, 36.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5507656901472834, var=0.1588117450044955\n",
            "                Prec@(1) = 0.40766733924028425\n",
            "                Prec@(5) = 0.72392315115361\n",
            "                Prec@(10) = 0.8152469514869726\n",
            "                Prec@(50) = 0.9495569786823406\n",
            "                NUMBER_OF_SAMPLES = 11399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11506it [05:17, 36.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5505846418759532, var=0.15871506094331725\n",
            "                Prec@(1) = 0.4072528045917036\n",
            "                Prec@(5) = 0.7239759979128619\n",
            "                Prec@(10) = 0.815375250021741\n",
            "                Prec@(50) = 0.9495608313766415\n",
            "                NUMBER_OF_SAMPLES = 11499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11607it [05:20, 39.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5505077940176671, var=0.15837430341304187\n",
            "                Prec@(1) = 0.40650056039313737\n",
            "                Prec@(5) = 0.7250625053883956\n",
            "                Prec@(10) = 0.815932407966204\n",
            "                Prec@(50) = 0.9499956892835589\n",
            "                NUMBER_OF_SAMPLES = 11599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11705it [05:23, 38.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5510999551185839, var=0.15805192245561134\n",
            "                Prec@(1) = 0.4064449952987435\n",
            "                Prec@(5) = 0.726386870672707\n",
            "                Prec@(10) = 0.8167364732028378\n",
            "                Prec@(50) = 0.9503376356953586\n",
            "                NUMBER_OF_SAMPLES = 11699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11806it [05:25, 35.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5502872448006247, var=0.1578727051542193\n",
            "                Prec@(1) = 0.4051190778879566\n",
            "                Prec@(5) = 0.7259089753368929\n",
            "                Prec@(10) = 0.8164251207729468\n",
            "                Prec@(50) = 0.950419527078566\n",
            "                NUMBER_OF_SAMPLES = 11799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11906it [05:28, 39.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5504289506992005, var=0.15759831334280153\n",
            "                Prec@(1) = 0.4047398941087486\n",
            "                Prec@(5) = 0.7266156819900832\n",
            "                Prec@(10) = 0.8171274897050173\n",
            "                Prec@(50) = 0.9508362047230859\n",
            "                NUMBER_OF_SAMPLES = 11899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12007it [05:31, 41.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.549837035268999, var=0.15756394505384436\n",
            "                Prec@(1) = 0.40403366947245606\n",
            "                Prec@(5) = 0.7262271855988\n",
            "                Prec@(10) = 0.8166513876156346\n",
            "                Prec@(50) = 0.9512459371614301\n",
            "                NUMBER_OF_SAMPLES = 11999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12104it [05:33, 35.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5480513047122876, var=0.1575271877376854\n",
            "                Prec@(1) = 0.40201669559467723\n",
            "                Prec@(5) = 0.7251012480370278\n",
            "                Prec@(10) = 0.8156045954211092\n",
            "                Prec@(50) = 0.9509876849326391\n",
            "                NUMBER_OF_SAMPLES = 12099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12208it [05:36, 40.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.547532297187253, var=0.15750699429288756\n",
            "                Prec@(1) = 0.40142634642183783\n",
            "                Prec@(5) = 0.7246495614394622\n",
            "                Prec@(10) = 0.8155586523485532\n",
            "                Prec@(50) = 0.9508976145585704\n",
            "                NUMBER_OF_SAMPLES = 12199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12306it [05:39, 37.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5479915191167598, var=0.157360770052511\n",
            "                Prec@(1) = 0.4017399788600699\n",
            "                Prec@(5) = 0.7257500609805675\n",
            "                Prec@(10) = 0.8164078380356127\n",
            "                Prec@(50) = 0.9511342385559801\n",
            "                NUMBER_OF_SAMPLES = 12299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12405it [05:41, 41.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5470736716978586, var=0.1574935911713614\n",
            "                Prec@(1) = 0.4009194289862086\n",
            "                Prec@(5) = 0.7247358657956287\n",
            "                Prec@(10) = 0.8153076861037181\n",
            "                Prec@(50) = 0.9503185740785547\n",
            "                NUMBER_OF_SAMPLES = 12399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12508it [05:44, 38.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5475364528406211, var=0.1578067314734916\n",
            "                Prec@(1) = 0.40203216257300584\n",
            "                Prec@(5) = 0.7244579566365309\n",
            "                Prec@(10) = 0.8148651892151372\n",
            "                Prec@(50) = 0.9499159932794624\n",
            "                NUMBER_OF_SAMPLES = 12499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12607it [05:46, 40.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5475414836978797, var=0.1579095297800893\n",
            "                Prec@(1) = 0.40225414715453606\n",
            "                Prec@(5) = 0.7239463449480118\n",
            "                Prec@(10) = 0.8148265735375824\n",
            "                Prec@(50) = 0.9499960314310659\n",
            "                NUMBER_OF_SAMPLES = 12599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12707it [05:49, 37.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5467033574124186, var=0.1578493116818348\n",
            "                Prec@(1) = 0.40121269391290654\n",
            "                Prec@(5) = 0.723285298054965\n",
            "                Prec@(10) = 0.8146310733128593\n",
            "                Prec@(50) = 0.9496023308921963\n",
            "                NUMBER_OF_SAMPLES = 12699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12805it [05:51, 40.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5478509088056905, var=0.15814425255716705\n",
            "                Prec@(1) = 0.40300023439331195\n",
            "                Prec@(5) = 0.7233377607625596\n",
            "                Prec@(10) = 0.8144386280178139\n",
            "                Prec@(50) = 0.9492147824048753\n",
            "                NUMBER_OF_SAMPLES = 12799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12905it [05:54, 39.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5478180568578354, var=0.1582746351705551\n",
            "                Prec@(1) = 0.4032095511279944\n",
            "                Prec@(5) = 0.72300178308396\n",
            "                Prec@(10) = 0.814094115822932\n",
            "                Prec@(50) = 0.9489107682766106\n",
            "                NUMBER_OF_SAMPLES = 12899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13007it [05:57, 37.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5486541724636675, var=0.15827061236504883\n",
            "                Prec@(1) = 0.4041849373028695\n",
            "                Prec@(5) = 0.7239787675975075\n",
            "                Prec@(10) = 0.8146780521578583\n",
            "                Prec@(50) = 0.9489960766212786\n",
            "                NUMBER_OF_SAMPLES = 12999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13106it [05:59, 41.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5492684341462927, var=0.15837173468251897\n",
            "                Prec@(1) = 0.4050690892434537\n",
            "                Prec@(5) = 0.7244827849454156\n",
            "                Prec@(10) = 0.8146423391098557\n",
            "                Prec@(50) = 0.9487747156271471\n",
            "                NUMBER_OF_SAMPLES = 13099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13205it [06:02, 38.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.549692639150919, var=0.15858828032965439\n",
            "                Prec@(1) = 0.40593984392757027\n",
            "                Prec@(5) = 0.7242972952496401\n",
            "                Prec@(10) = 0.8144556405788317\n",
            "                Prec@(50) = 0.9483294188953708\n",
            "                NUMBER_OF_SAMPLES = 13199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13306it [06:04, 39.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5497228354655205, var=0.1588252993845177\n",
            "                Prec@(1) = 0.4064215354537935\n",
            "                Prec@(5) = 0.7238890142115949\n",
            "                Prec@(10) = 0.8139709752612978\n",
            "                Prec@(50) = 0.9476652379878187\n",
            "                NUMBER_OF_SAMPLES = 13299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13404it [06:07, 40.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5498980882561718, var=0.15877170045144037\n",
            "                Prec@(1) = 0.4065228748414061\n",
            "                Prec@(5) = 0.7241585192924845\n",
            "                Prec@(10) = 0.8143145010821703\n",
            "                Prec@(50) = 0.9476826628852899\n",
            "                NUMBER_OF_SAMPLES = 13399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13507it [06:09, 38.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5496972020825586, var=0.15877717560601406\n",
            "                Prec@(1) = 0.4063263945477443\n",
            "                Prec@(5) = 0.7237573153566931\n",
            "                Prec@(10) = 0.8142825394473665\n",
            "                Prec@(50) = 0.9477739091784577\n",
            "                NUMBER_OF_SAMPLES = 13499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13605it [06:12, 39.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5493297066457379, var=0.15886522979446183\n",
            "                Prec@(1) = 0.40613280388263845\n",
            "                Prec@(5) = 0.723288477093904\n",
            "                Prec@(10) = 0.814030443414957\n",
            "                Prec@(50) = 0.9476432090594896\n",
            "                NUMBER_OF_SAMPLES = 13599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13704it [06:14, 37.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5497783251576748, var=0.1589898566343795\n",
            "                Prec@(1) = 0.40689101394262356\n",
            "                Prec@(5) = 0.7235564639754727\n",
            "                Prec@(10) = 0.8138550259143004\n",
            "                Prec@(50) = 0.9474414190816848\n",
            "                NUMBER_OF_SAMPLES = 13699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13806it [06:17, 35.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5493167036434426, var=0.15899535246133845\n",
            "                Prec@(1) = 0.40633379230379013\n",
            "                Prec@(5) = 0.7230958765127908\n",
            "                Prec@(10) = 0.8135372128415103\n",
            "                Prec@(50) = 0.947242553808247\n",
            "                NUMBER_OF_SAMPLES = 13799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13904it [06:20, 40.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5496647748115412, var=0.159092523205346\n",
            "                Prec@(1) = 0.40679185552917474\n",
            "                Prec@(5) = 0.7232174976617023\n",
            "                Prec@(10) = 0.8132239729476941\n",
            "                Prec@(50) = 0.9462551262680768\n",
            "                NUMBER_OF_SAMPLES = 13899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14005it [06:22, 38.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5486752241385232, var=0.1590250567676303\n",
            "                Prec@(1) = 0.4054575326809058\n",
            "                Prec@(5) = 0.7224801771555112\n",
            "                Prec@(10) = 0.8124151725123223\n",
            "                Prec@(50) = 0.945496106864776\n",
            "                NUMBER_OF_SAMPLES = 13999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14106it [06:25, 35.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5495259948794916, var=0.15896610652695936\n",
            "                Prec@(1) = 0.4062699482232782\n",
            "                Prec@(5) = 0.7233137101922122\n",
            "                Prec@(10) = 0.812965458543159\n",
            "                Prec@(50) = 0.9455989786509682\n",
            "                NUMBER_OF_SAMPLES = 14099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14205it [06:28, 36.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5502243409195997, var=0.158945319067464\n",
            "                Prec@(1) = 0.40693006549757027\n",
            "                Prec@(5) = 0.7238537925206\n",
            "                Prec@(10) = 0.8131558560462004\n",
            "                Prec@(50) = 0.9454891189520389\n",
            "                NUMBER_OF_SAMPLES = 14199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14306it [06:30, 35.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5507443781420093, var=0.15902117177718927\n",
            "                Prec@(1) = 0.4075809497167634\n",
            "                Prec@(5) = 0.7241765158402685\n",
            "                Prec@(10) = 0.8130638506189244\n",
            "                Prec@(50) = 0.9449611860969298\n",
            "                NUMBER_OF_SAMPLES = 14299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14407it [06:33, 35.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5514290524755551, var=0.1592306074396274\n",
            "                Prec@(1) = 0.40877838738801303\n",
            "                Prec@(5) = 0.7241475102437669\n",
            "                Prec@(10) = 0.8129036738662407\n",
            "                Prec@(50) = 0.9449267310229877\n",
            "                NUMBER_OF_SAMPLES = 14399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14506it [06:36, 37.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5514178135853829, var=0.15906462506362395\n",
            "                Prec@(1) = 0.4085109317883992\n",
            "                Prec@(5) = 0.7249465480377957\n",
            "                Prec@(10) = 0.813642320160011\n",
            "                Prec@(50) = 0.9451686323194703\n",
            "                NUMBER_OF_SAMPLES = 14499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14606it [06:39, 38.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5515598891168193, var=0.159186123395341\n",
            "                Prec@(1) = 0.4089321186382629\n",
            "                Prec@(5) = 0.7248441674087266\n",
            "                Prec@(10) = 0.8136173710528118\n",
            "                Prec@(50) = 0.9452017261456264\n",
            "                NUMBER_OF_SAMPLES = 14599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14706it [06:41, 35.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5520458692582746, var=0.15930073411645232\n",
            "                Prec@(1) = 0.40968773385944623\n",
            "                Prec@(5) = 0.7251513708415539\n",
            "                Prec@(10) = 0.8135927614123409\n",
            "                Prec@(50) = 0.9450983060072113\n",
            "                NUMBER_OF_SAMPLES = 14699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14806it [06:44, 35.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.55197982751722, var=0.1593815770945258\n",
            "                Prec@(1) = 0.4097574160416244\n",
            "                Prec@(5) = 0.7246435569970944\n",
            "                Prec@(10) = 0.8132981958240422\n",
            "                Prec@(50) = 0.9449287113994189\n",
            "                NUMBER_OF_SAMPLES = 14799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14905it [06:47, 37.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5521640570734464, var=0.15941799044957156\n",
            "                Prec@(1) = 0.41009463722397477\n",
            "                Prec@(5) = 0.7248808644875495\n",
            "                Prec@(10) = 0.813544533190147\n",
            "                Prec@(50) = 0.9450298677763608\n",
            "                NUMBER_OF_SAMPLES = 14899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15007it [06:49, 39.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5519939587406508, var=0.15955033861168216\n",
            "                Prec@(1) = 0.4101606773784919\n",
            "                Prec@(5) = 0.7243149543302887\n",
            "                Prec@(10) = 0.8129875325021668\n",
            "                Prec@(50) = 0.9451963464230949\n",
            "                NUMBER_OF_SAMPLES = 14999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15107it [06:52, 39.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5512757763259543, var=0.1595698717030234\n",
            "                Prec@(1) = 0.4093648585999073\n",
            "                Prec@(5) = 0.7237565401682231\n",
            "                Prec@(10) = 0.8123716802437247\n",
            "                Prec@(50) = 0.9447645539439699\n",
            "                NUMBER_OF_SAMPLES = 15099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15204it [06:54, 41.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5511388628406755, var=0.15960121664594037\n",
            "                Prec@(1) = 0.4092374498322258\n",
            "                Prec@(5) = 0.723600236857688\n",
            "                Prec@(10) = 0.8121586946509639\n",
            "                Prec@(50) = 0.9445358247253108\n",
            "                NUMBER_OF_SAMPLES = 15199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15303it [06:57, 37.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5506141327564809, var=0.1595892127791691\n",
            "                Prec@(1) = 0.40858879665337605\n",
            "                Prec@(5) = 0.7231845218641741\n",
            "                Prec@(10) = 0.8118177658670501\n",
            "                Prec@(50) = 0.9443100856265115\n",
            "                NUMBER_OF_SAMPLES = 15299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15404it [07:00, 35.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5498067892414656, var=0.15954153622284345\n",
            "                Prec@(1) = 0.4075589323982077\n",
            "                Prec@(5) = 0.7227742061172804\n",
            "                Prec@(10) = 0.8113513864536658\n",
            "                Prec@(50) = 0.9440223391129294\n",
            "                NUMBER_OF_SAMPLES = 15399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15506it [07:03, 37.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5492376247058388, var=0.15973193980021919\n",
            "                Prec@(1) = 0.4071875604877734\n",
            "                Prec@(5) = 0.7216594619007678\n",
            "                Prec@(10) = 0.8100522614362217\n",
            "                Prec@(50) = 0.9435447448222466\n",
            "                NUMBER_OF_SAMPLES = 15499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15606it [07:05, 37.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5500699574201794, var=0.15979365786121877\n",
            "                Prec@(1) = 0.408231296878005\n",
            "                Prec@(5) = 0.7222257837040836\n",
            "                Prec@(10) = 0.8105006731200718\n",
            "                Prec@(50) = 0.9436502339893583\n",
            "                NUMBER_OF_SAMPLES = 15599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15704it [07:08, 36.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5501624322259232, var=0.1598162175232505\n",
            "                Prec@(1) = 0.4083699598700554\n",
            "                Prec@(5) = 0.7222116058347665\n",
            "                Prec@(10) = 0.8106248805656411\n",
            "                Prec@(50) = 0.9436269826103574\n",
            "                NUMBER_OF_SAMPLES = 15699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15805it [07:10, 35.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5501265718314886, var=0.15999593816263405\n",
            "                Prec@(1) = 0.40869675295904806\n",
            "                Prec@(5) = 0.7216912462814102\n",
            "                Prec@(10) = 0.8102411545034496\n",
            "                Prec@(50) = 0.9436673207165011\n",
            "                NUMBER_OF_SAMPLES = 15799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15903it [07:13, 27.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5510607939623384, var=0.1600060759555185\n",
            "                Prec@(1) = 0.4097741996351972\n",
            "                Prec@(5) = 0.7226240644065665\n",
            "                Prec@(10) = 0.8107428140134599\n",
            "                Prec@(50) = 0.9438329454682685\n",
            "                NUMBER_OF_SAMPLES = 15899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16004it [07:17, 25.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5510145344051837, var=0.1599534693337227\n",
            "                Prec@(1) = 0.4096506031626977\n",
            "                Prec@(5) = 0.7227951746984187\n",
            "                Prec@(10) = 0.8109881867616726\n",
            "                Prec@(50) = 0.9437464841552597\n",
            "                NUMBER_OF_SAMPLES = 15999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16104it [07:21, 34.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5504755530702432, var=0.15991110603565842\n",
            "                Prec@(1) = 0.40896950121125536\n",
            "                Prec@(5) = 0.7225293496490465\n",
            "                Prec@(10) = 0.8109820485744457\n",
            "                Prec@(50) = 0.9435368656438288\n",
            "                NUMBER_OF_SAMPLES = 16099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16207it [07:24, 36.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5510719876885986, var=0.1598990871920792\n",
            "                Prec@(1) = 0.40965491697018336\n",
            "                Prec@(5) = 0.7232545218840669\n",
            "                Prec@(10) = 0.811593308228903\n",
            "                Prec@(50) = 0.9435767639977777\n",
            "                NUMBER_OF_SAMPLES = 16199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16304it [07:26, 36.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5516439397749471, var=0.15983658220629207\n",
            "                Prec@(1) = 0.41020921528928156\n",
            "                Prec@(5) = 0.7239094422970734\n",
            "                Prec@(10) = 0.8123197742192773\n",
            "                Prec@(50) = 0.9437388796858703\n",
            "                NUMBER_OF_SAMPLES = 16299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16407it [07:29, 36.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.552351055178886, var=0.15985423270235993\n",
            "                Prec@(1) = 0.4110616501006159\n",
            "                Prec@(5) = 0.7246783340447588\n",
            "                Prec@(10) = 0.8127324836880297\n",
            "                Prec@(50) = 0.9436551009207879\n",
            "                NUMBER_OF_SAMPLES = 16399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16504it [07:32, 37.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5529243231402439, var=0.15998878999446087\n",
            "                Prec@(1) = 0.4119643614764531\n",
            "                Prec@(5) = 0.7247105885205164\n",
            "                Prec@(10) = 0.8127159221771016\n",
            "                Prec@(50) = 0.9436329474513607\n",
            "                NUMBER_OF_SAMPLES = 16499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16604it [07:34, 36.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5531924062716264, var=0.16007538880817898\n",
            "                Prec@(1) = 0.41243448400506055\n",
            "                Prec@(5) = 0.7249231881438641\n",
            "                Prec@(10) = 0.812639315621423\n",
            "                Prec@(50) = 0.943490571721188\n",
            "                NUMBER_OF_SAMPLES = 16599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16704it [07:37, 34.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5534977156932988, var=0.16023284289894144\n",
            "                Prec@(1) = 0.41301874363734353\n",
            "                Prec@(5) = 0.724833822384574\n",
            "                Prec@(10) = 0.8120845559614348\n",
            "                Prec@(50) = 0.9430504820647942\n",
            "                NUMBER_OF_SAMPLES = 16699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16804it [07:40, 36.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5537904162131674, var=0.16024423515483563\n",
            "                Prec@(1) = 0.41335793797249837\n",
            "                Prec@(5) = 0.7251622120364307\n",
            "                Prec@(10) = 0.8121912018572534\n",
            "                Prec@(50) = 0.9429132686469432\n",
            "                NUMBER_OF_SAMPLES = 16799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16905it [07:43, 37.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5543715044614476, var=0.1603704886546389\n",
            "                Prec@(1) = 0.41422569382803714\n",
            "                Prec@(5) = 0.7254275400911296\n",
            "                Prec@(10) = 0.8122374104976626\n",
            "                Prec@(50) = 0.9426001538552577\n",
            "                NUMBER_OF_SAMPLES = 16899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17005it [07:45, 37.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5540962308009615, var=0.16054794256088958\n",
            "                Prec@(1) = 0.4142596623330784\n",
            "                Prec@(5) = 0.724748514618507\n",
            "                Prec@(10) = 0.8115771515971528\n",
            "                Prec@(50) = 0.9425260309429967\n",
            "                NUMBER_OF_SAMPLES = 16999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17104it [07:48, 38.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5548561531878375, var=0.16062351648421977\n",
            "                Prec@(1) = 0.41528744371015847\n",
            "                Prec@(5) = 0.7251886075209076\n",
            "                Prec@(10) = 0.8120357915667583\n",
            "                Prec@(50) = 0.9425112579683023\n",
            "                NUMBER_OF_SAMPLES = 17099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17205it [07:50, 37.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5552312953457339, var=0.16069117975028413\n",
            "                Prec@(1) = 0.41577998720855863\n",
            "                Prec@(5) = 0.7251584394441537\n",
            "                Prec@(10) = 0.8118495261352404\n",
            "                Prec@(50) = 0.942496656782371\n",
            "                NUMBER_OF_SAMPLES = 17199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17307it [07:53, 38.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5556254759466285, var=0.16070905565881172\n",
            "                Prec@(1) = 0.4162668362333083\n",
            "                Prec@(5) = 0.725186426961096\n",
            "                Prec@(10) = 0.8121856754725707\n",
            "                Prec@(50) = 0.9426556448349616\n",
            "                NUMBER_OF_SAMPLES = 17299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17405it [07:56, 37.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5565258038878762, var=0.16084504568366373\n",
            "                Prec@(1) = 0.4175527329156848\n",
            "                Prec@(5) = 0.7256164147364791\n",
            "                Prec@(10) = 0.8124604862348411\n",
            "                Prec@(50) = 0.9424679579286166\n",
            "                NUMBER_OF_SAMPLES = 17399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17504it [07:58, 36.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5571217628203593, var=0.1608347557279569\n",
            "                Prec@(1) = 0.4181953254471684\n",
            "                Prec@(5) = 0.7261557803303046\n",
            "                Prec@(10) = 0.8125607177553003\n",
            "                Prec@(50) = 0.9427395851191497\n",
            "                NUMBER_OF_SAMPLES = 17499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17605it [08:01, 37.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5578182046293789, var=0.16082054498604137\n",
            "                Prec@(1) = 0.41900107960679583\n",
            "                Prec@(5) = 0.727029944883232\n",
            "                Prec@(10) = 0.8130575600886414\n",
            "                Prec@(50) = 0.9427808398204444\n",
            "                NUMBER_OF_SAMPLES = 17599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17706it [08:04, 36.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5590256816908933, var=0.1608765304615446\n",
            "                Prec@(1) = 0.4204757330922651\n",
            "                Prec@(5) = 0.7278942313125035\n",
            "                Prec@(10) = 0.81349228769987\n",
            "                Prec@(50) = 0.9426521272388271\n",
            "                NUMBER_OF_SAMPLES = 17699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17807it [08:07, 39.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.559547824618571, var=0.1609266280556955\n",
            "                Prec@(1) = 0.4211472554637901\n",
            "                Prec@(5) = 0.7282431597280746\n",
            "                Prec@(10) = 0.813585032867015\n",
            "                Prec@(50) = 0.9423001292207427\n",
            "                NUMBER_OF_SAMPLES = 17799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17906it [08:09, 36.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5596366546000533, var=0.16105560973476332\n",
            "                Prec@(1) = 0.4214760601150902\n",
            "                Prec@(5) = 0.727917760768758\n",
            "                Prec@(10) = 0.813229789373708\n",
            "                Prec@(50) = 0.9421196714900274\n",
            "                NUMBER_OF_SAMPLES = 17899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18005it [08:12, 39.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5605430687900042, var=0.1611240070932887\n",
            "                Prec@(1) = 0.42269014945274735\n",
            "                Prec@(5) = 0.7285960331129507\n",
            "                Prec@(10) = 0.8137118728818268\n",
            "                Prec@(50) = 0.9420523362409022\n",
            "                NUMBER_OF_SAMPLES = 17999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18104it [08:14, 36.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5604580397737745, var=0.1611595188963585\n",
            "                Prec@(1) = 0.4226752859273993\n",
            "                Prec@(5) = 0.7284380352505664\n",
            "                Prec@(10) = 0.8136361124924029\n",
            "                Prec@(50) = 0.9419304933974253\n",
            "                NUMBER_OF_SAMPLES = 18099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18207it [08:17, 36.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5607831144649738, var=0.1611994237666763\n",
            "                Prec@(1) = 0.4231551184130996\n",
            "                Prec@(5) = 0.728666410242321\n",
            "                Prec@(10) = 0.813726028902687\n",
            "                Prec@(50) = 0.9420297818561459\n",
            "                NUMBER_OF_SAMPLES = 18199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18306it [08:20, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5616414595316732, var=0.16141376793662718\n",
            "                Prec@(1) = 0.4245587190556861\n",
            "                Prec@(5) = 0.7288376414011695\n",
            "                Prec@(10) = 0.8136510191813761\n",
            "                Prec@(50) = 0.9419093939559539\n",
            "                NUMBER_OF_SAMPLES = 18299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18407it [08:23, 37.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5626077607447736, var=0.1615995725239089\n",
            "                Prec@(1) = 0.426055763900212\n",
            "                Prec@(5) = 0.7291157128104788\n",
            "                Prec@(10) = 0.8136855263873036\n",
            "                Prec@(50) = 0.9419533670308169\n",
            "                NUMBER_OF_SAMPLES = 18399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18504it [08:25, 38.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5629887170720163, var=0.16165984428287133\n",
            "                Prec@(1) = 0.42661765500837884\n",
            "                Prec@(5) = 0.7293907778798854\n",
            "                Prec@(10) = 0.8137737174982431\n",
            "                Prec@(50) = 0.9417806367911778\n",
            "                NUMBER_OF_SAMPLES = 18499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18607it [08:28, 38.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5628853008182805, var=0.1619164126809274\n",
            "                Prec@(1) = 0.4269584386257326\n",
            "                Prec@(5) = 0.7286950911339319\n",
            "                Prec@(10) = 0.8130006989623098\n",
            "                Prec@(50) = 0.9412871659766654\n",
            "                NUMBER_OF_SAMPLES = 18599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18705it [08:31, 36.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5630913814621974, var=0.16209556668149924\n",
            "                Prec@(1) = 0.4275094924862292\n",
            "                Prec@(5) = 0.7284346756511043\n",
            "                Prec@(10) = 0.8124498636290711\n",
            "                Prec@(50) = 0.9407989732071234\n",
            "                NUMBER_OF_SAMPLES = 18699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18807it [08:33, 38.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5628524643838431, var=0.16197223479063205\n",
            "                Prec@(1) = 0.4269907973828395\n",
            "                Prec@(5) = 0.7286557795627427\n",
            "                Prec@(10) = 0.8126496090217564\n",
            "                Prec@(50) = 0.9409011117612639\n",
            "                NUMBER_OF_SAMPLES = 18799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18906it [08:36, 39.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5629820671542282, var=0.16209111094142423\n",
            "                Prec@(1) = 0.4273771098999947\n",
            "                Prec@(5) = 0.7286099793639875\n",
            "                Prec@(10) = 0.8123181120694216\n",
            "                Prec@(50) = 0.9406317794592306\n",
            "                NUMBER_OF_SAMPLES = 18899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19003it [08:38, 36.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5631814011246449, var=0.16221155650693297\n",
            "                Prec@(1) = 0.42781199010474236\n",
            "                Prec@(5) = 0.728564661297963\n",
            "                Prec@(10) = 0.8121480077898837\n",
            "                Prec@(50) = 0.9399442075898732\n",
            "                NUMBER_OF_SAMPLES = 18999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19104it [08:41, 36.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.563487160174282, var=0.16207476409360275\n",
            "                Prec@(1) = 0.42787580501596945\n",
            "                Prec@(5) = 0.7290957641761349\n",
            "                Prec@(10) = 0.8125556311848788\n",
            "                Prec@(50) = 0.9400492172365045\n",
            "                NUMBER_OF_SAMPLES = 19099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19207it [08:44, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5642992767639041, var=0.1621041642218618\n",
            "                Prec@(1) = 0.42892859003073075\n",
            "                Prec@(5) = 0.729777592582947\n",
            "                Prec@(10) = 0.813115266420126\n",
            "                Prec@(50) = 0.9401010469295276\n",
            "                NUMBER_OF_SAMPLES = 19199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19305it [08:46, 36.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5648320976413385, var=0.1620705023204369\n",
            "                Prec@(1) = 0.42950411938442407\n",
            "                Prec@(5) = 0.7304005388880253\n",
            "                Prec@(10) = 0.8134618374009016\n",
            "                Prec@(50) = 0.9402041556557335\n",
            "                NUMBER_OF_SAMPLES = 19299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19404it [08:49, 38.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5649485186534072, var=0.16217630792512266\n",
            "                Prec@(1) = 0.4298675189442755\n",
            "                Prec@(5) = 0.7299345327078716\n",
            "                Prec@(10) = 0.8135986391051085\n",
            "                Prec@(50) = 0.940254652301665\n",
            "                NUMBER_OF_SAMPLES = 19399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19507it [08:52, 36.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5650876245344238, var=0.1624175168540025\n",
            "                Prec@(1) = 0.4304323298630699\n",
            "                Prec@(5) = 0.7295245910046669\n",
            "                Prec@(10) = 0.8129647674239705\n",
            "                Prec@(50) = 0.9395353607877327\n",
            "                NUMBER_OF_SAMPLES = 19499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19604it [08:54, 35.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5652713819743146, var=0.1624127020464181\n",
            "                Prec@(1) = 0.43063421603143015\n",
            "                Prec@(5) = 0.7297821317414154\n",
            "                Prec@(10) = 0.813051686310526\n",
            "                Prec@(50) = 0.9392826164600234\n",
            "                NUMBER_OF_SAMPLES = 19599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19705it [08:57, 37.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5662039159684452, var=0.1624897629344094\n",
            "                Prec@(1) = 0.43190009645159655\n",
            "                Prec@(5) = 0.7303924057058734\n",
            "                Prec@(10) = 0.813442306716077\n",
            "                Prec@(50) = 0.9394385501802122\n",
            "                NUMBER_OF_SAMPLES = 19699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19805it [09:00, 36.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.566041926647979, var=0.16263348896686286\n",
            "                Prec@(1) = 0.4319915147229658\n",
            "                Prec@(5) = 0.7299863629476236\n",
            "                Prec@(10) = 0.8129703520379817\n",
            "                Prec@(50) = 0.9393403707257942\n",
            "                NUMBER_OF_SAMPLES = 19799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19906it [09:02, 37.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5655412856495338, var=0.16265582342815565\n",
            "                Prec@(1) = 0.43142871501080454\n",
            "                Prec@(5) = 0.7295844012261923\n",
            "                Prec@(10) = 0.8125031408613498\n",
            "                Prec@(50) = 0.9391929242675512\n",
            "                NUMBER_OF_SAMPLES = 19899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20008it [09:05, 40.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5658673251858949, var=0.16261217452479182\n",
            "                Prec@(1) = 0.431771588579429\n",
            "                Prec@(5) = 0.7301365068253413\n",
            "                Prec@(10) = 0.8128906445322266\n",
            "                Prec@(50) = 0.9394469723486174\n",
            "                NUMBER_OF_SAMPLES = 19999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20105it [09:08, 37.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5663427238408505, var=0.1625946424195075\n",
            "                Prec@(1) = 0.432310065177372\n",
            "                Prec@(5) = 0.7306333648440221\n",
            "                Prec@(10) = 0.8131747848151649\n",
            "                Prec@(50) = 0.9395989850241305\n",
            "                NUMBER_OF_SAMPLES = 20099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20208it [09:10, 39.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5668037175898661, var=0.1624933544498561\n",
            "                Prec@(1) = 0.4326451804544779\n",
            "                Prec@(5) = 0.7311748106341898\n",
            "                Prec@(10) = 0.81370364869548\n",
            "                Prec@(50) = 0.9397494925491361\n",
            "                NUMBER_OF_SAMPLES = 20199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20305it [09:13, 37.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5670225362646587, var=0.16250213668612887\n",
            "                Prec@(1) = 0.4329769939405882\n",
            "                Prec@(5) = 0.7313660771466575\n",
            "                Prec@(10) = 0.8139809842849401\n",
            "                Prec@(50) = 0.9399477806788512\n",
            "                NUMBER_OF_SAMPLES = 20299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20403it [09:15, 37.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5670833577200364, var=0.16254491464767087\n",
            "                Prec@(1) = 0.43315848816118435\n",
            "                Prec@(5) = 0.7310652482964851\n",
            "                Prec@(10) = 0.8141575567429776\n",
            "                Prec@(50) = 0.9400951027011129\n",
            "                NUMBER_OF_SAMPLES = 20399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20503it [09:18, 37.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5676264783722685, var=0.1624645462443071\n",
            "                Prec@(1) = 0.43363090882482075\n",
            "                Prec@(5) = 0.7316454461193229\n",
            "                Prec@(10) = 0.8146738865310503\n",
            "                Prec@(50) = 0.9402897702326943\n",
            "                NUMBER_OF_SAMPLES = 20499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20605it [09:21, 34.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5684397742839178, var=0.16245801704825297\n",
            "                Prec@(1) = 0.43458420311665613\n",
            "                Prec@(5) = 0.7321714646342056\n",
            "                Prec@(10) = 0.8150881110733531\n",
            "                Prec@(50) = 0.9405310937424147\n",
            "                NUMBER_OF_SAMPLES = 20599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20705it [09:24, 36.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5691782160365849, var=0.16260247336213543\n",
            "                Prec@(1) = 0.4357215324411807\n",
            "                Prec@(5) = 0.7323542200106286\n",
            "                Prec@(10) = 0.8149669066138461\n",
            "                Prec@(50) = 0.9403352818976762\n",
            "                NUMBER_OF_SAMPLES = 20699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20804it [09:26, 36.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5700177613914694, var=0.16265293238156298\n",
            "                Prec@(1) = 0.43684792538102796\n",
            "                Prec@(5) = 0.7330160103851147\n",
            "                Prec@(10) = 0.8153276599836531\n",
            "                Prec@(50) = 0.9404298283571325\n",
            "                NUMBER_OF_SAMPLES = 20799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20905it [09:29, 35.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5704792223920365, var=0.1626391169986617\n",
            "                Prec@(1) = 0.43738934877266855\n",
            "                Prec@(5) = 0.7332886740992391\n",
            "                Prec@(10) = 0.8157328101823054\n",
            "                Prec@(50) = 0.9406191683812622\n",
            "                NUMBER_OF_SAMPLES = 20899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21005it [09:32, 36.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5714043977940895, var=0.1626839339103829\n",
            "                Prec@(1) = 0.4385923139197105\n",
            "                Prec@(5) = 0.7339873327301301\n",
            "                Prec@(10) = 0.8160864803085861\n",
            "                Prec@(50) = 0.9406162198199914\n",
            "                NUMBER_OF_SAMPLES = 20999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21106it [09:34, 35.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5713391684014608, var=0.16272676964724644\n",
            "                Prec@(1) = 0.43859898573392103\n",
            "                Prec@(5) = 0.7335892696336319\n",
            "                Prec@(10) = 0.8160576330631784\n",
            "                Prec@(50) = 0.9407080904308261\n",
            "                NUMBER_OF_SAMPLES = 21099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21206it [09:37, 35.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5711823293966813, var=0.1626292232805651\n",
            "                Prec@(1) = 0.43822821831218456\n",
            "                Prec@(5) = 0.7337610264635124\n",
            "                Prec@(10) = 0.8160762300108496\n",
            "                Prec@(50) = 0.9407990942969008\n",
            "                NUMBER_OF_SAMPLES = 21199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21305it [09:40, 37.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5712055982882389, var=0.1627512305733145\n",
            "                Prec@(1) = 0.4384712897319123\n",
            "                Prec@(5) = 0.7333208131837176\n",
            "                Prec@(10) = 0.8158598995257993\n",
            "                Prec@(50) = 0.9405605896990469\n",
            "                NUMBER_OF_SAMPLES = 21299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21406it [09:43, 38.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5714362655331098, var=0.16282225261678246\n",
            "                Prec@(1) = 0.43885228281695404\n",
            "                Prec@(5) = 0.7333520257955979\n",
            "                Prec@(10) = 0.8156455909154633\n",
            "                Prec@(50) = 0.9401841207533063\n",
            "                NUMBER_OF_SAMPLES = 21399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21506it [09:45, 37.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5720090586374276, var=0.16280943529719705\n",
            "                Prec@(1) = 0.4395088143634588\n",
            "                Prec@(5) = 0.7338945997488255\n",
            "                Prec@(10) = 0.8158519000883762\n",
            "                Prec@(50) = 0.9402297781292153\n",
            "                NUMBER_OF_SAMPLES = 21499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21604it [09:48, 38.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5716880612129966, var=0.16266904952667305\n",
            "                Prec@(1) = 0.4388166118801796\n",
            "                Prec@(5) = 0.7339691652391315\n",
            "                Prec@(10) = 0.8159637020232419\n",
            "                Prec@(50) = 0.9401361174128432\n",
            "                NUMBER_OF_SAMPLES = 21599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21708it [09:51, 41.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5716049672393527, var=0.1626926482144966\n",
            "                Prec@(1) = 0.43877598045992905\n",
            "                Prec@(5) = 0.7337665330199549\n",
            "                Prec@(10) = 0.8160283884049956\n",
            "                Prec@(50) = 0.9401815751877967\n",
            "                NUMBER_OF_SAMPLES = 21699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21804it [09:53, 39.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5709619629359534, var=0.16277884880358945\n",
            "                Prec@(1) = 0.43818523785494745\n",
            "                Prec@(5) = 0.7329235286022294\n",
            "                Prec@(10) = 0.8154502500114684\n",
            "                Prec@(50) = 0.9402266158998119\n",
            "                NUMBER_OF_SAMPLES = 21799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21908it [09:56, 41.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5700876413862067, var=0.1628072738719017\n",
            "                Prec@(1) = 0.43728024110689984\n",
            "                Prec@(5) = 0.7321338873921184\n",
            "                Prec@(10) = 0.8155623544454085\n",
            "                Prec@(50) = 0.9401799168911823\n",
            "                NUMBER_OF_SAMPLES = 21899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22007it [09:58, 35.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5709758008565536, var=0.1627852872548197\n",
            "                Prec@(1) = 0.43829264966589393\n",
            "                Prec@(5) = 0.732806036638029\n",
            "                Prec@(10) = 0.8159916359834538\n",
            "                Prec@(50) = 0.9404063821082776\n",
            "                NUMBER_OF_SAMPLES = 21999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22105it [10:01, 41.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5709835856756136, var=0.16268969046626397\n",
            "                Prec@(1) = 0.4381646228336124\n",
            "                Prec@(5) = 0.7331553463957645\n",
            "                Prec@(10) = 0.816462283361238\n",
            "                Prec@(50) = 0.9406307977736549\n",
            "                NUMBER_OF_SAMPLES = 22099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22204it [10:03, 36.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5719322989766449, var=0.1626615073102247\n",
            "                Prec@(1) = 0.4392540204513717\n",
            "                Prec@(5) = 0.7339519798189108\n",
            "                Prec@(10) = 0.8170187846299383\n",
            "                Prec@(50) = 0.940808144511014\n",
            "                NUMBER_OF_SAMPLES = 22199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22302it [10:07, 25.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5727843729955604, var=0.1625858799283949\n",
            "                Prec@(1) = 0.4401542670074891\n",
            "                Prec@(5) = 0.7346517781066415\n",
            "                Prec@(10) = 0.8177945199336293\n",
            "                Prec@(50) = 0.9410735907439796\n",
            "                NUMBER_OF_SAMPLES = 22299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22403it [10:10, 23.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.572967570749467, var=0.16259175897904019\n",
            "                Prec@(1) = 0.4403768025358275\n",
            "                Prec@(5) = 0.7346310103129604\n",
            "                Prec@(10) = 0.8178490111165677\n",
            "                Prec@(50) = 0.9411580874146167\n",
            "                NUMBER_OF_SAMPLES = 22399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22506it [10:14, 39.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5729376869578855, var=0.162485880908458\n",
            "                Prec@(1) = 0.44015289568425264\n",
            "                Prec@(5) = 0.7349215520689808\n",
            "                Prec@(10) = 0.8182141428507934\n",
            "                Prec@(50) = 0.9412862793901952\n",
            "                NUMBER_OF_SAMPLES = 22499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22606it [10:16, 38.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5731086278849692, var=0.16235910372420775\n",
            "                Prec@(1) = 0.44010796937917607\n",
            "                Prec@(5) = 0.7352980220363733\n",
            "                Prec@(10) = 0.8186202929333156\n",
            "                Prec@(50) = 0.941413336873313\n",
            "                NUMBER_OF_SAMPLES = 22599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22705it [10:19, 36.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5737291250740154, var=0.16242529743365575\n",
            "                Prec@(1) = 0.4409885898057183\n",
            "                Prec@(5) = 0.735627120137451\n",
            "                Prec@(10) = 0.8188907000308384\n",
            "                Prec@(50) = 0.9412749460328649\n",
            "                NUMBER_OF_SAMPLES = 22699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22806it [10:22, 38.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5739615399377793, var=0.16256141641186253\n",
            "                Prec@(1) = 0.44151059256984954\n",
            "                Prec@(5) = 0.7355585771305759\n",
            "                Prec@(10) = 0.8185446730119742\n",
            "                Prec@(50) = 0.9407430150445195\n",
            "                NUMBER_OF_SAMPLES = 22799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22904it [10:24, 33.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5743580855983664, var=0.16254370055289075\n",
            "                Prec@(1) = 0.4419843661295253\n",
            "                Prec@(5) = 0.736014673129831\n",
            "                Prec@(10) = 0.8188567186340014\n",
            "                Prec@(50) = 0.9408271103541639\n",
            "                NUMBER_OF_SAMPLES = 22899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23007it [10:27, 38.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5747582045022721, var=0.16257224497203332\n",
            "                Prec@(1) = 0.44254098004261055\n",
            "                Prec@(5) = 0.7361189616939867\n",
            "                Prec@(10) = 0.8191225705465455\n",
            "                Prec@(50) = 0.9409104743684508\n",
            "                NUMBER_OF_SAMPLES = 22999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23106it [10:30, 39.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5746086991592844, var=0.16254889658692268\n",
            "                Prec@(1) = 0.4423135200658037\n",
            "                Prec@(5) = 0.7358760119485692\n",
            "                Prec@(10) = 0.8191696610242868\n",
            "                Prec@(50) = 0.9409065327503355\n",
            "                NUMBER_OF_SAMPLES = 23099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23207it [10:32, 36.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5748811844382591, var=0.16256402406407885\n",
            "                Prec@(1) = 0.44264839001681106\n",
            "                Prec@(5) = 0.7360231044441571\n",
            "                Prec@(10) = 0.8192594508383982\n",
            "                Prec@(50) = 0.940816414500625\n",
            "                NUMBER_OF_SAMPLES = 23199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23306it [10:35, 34.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.574870942452014, var=0.1624359015719453\n",
            "                Prec@(1) = 0.4424224215631572\n",
            "                Prec@(5) = 0.7364693763680845\n",
            "                Prec@(10) = 0.8196059916734624\n",
            "                Prec@(50) = 0.9410275119103825\n",
            "                NUMBER_OF_SAMPLES = 23299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23399it [10:38, 36.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        MRR: mean=0.5751397217488267, var=0.1624051934618394\n",
            "        Prec@(1) = 0.44268740918027183\n",
            "        Prec@(5) = 0.7366441576203094\n",
            "        Prec@(10) = 0.8198563979827336\n",
            "        Prec@(50) = 0.9411060774425165\n",
            "        NUMBER_OF_SAMPLES = 23398\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "107it [00:02, 37.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6575746059496059, var=0.14555358455993658\n",
            "                Prec@(1) = 0.5252525252525253\n",
            "                Prec@(5) = 0.8080808080808081\n",
            "                Prec@(10) = 0.8888888888888888\n",
            "                Prec@(50) = 0.9696969696969697\n",
            "                NUMBER_OF_SAMPLES = 99\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "205it [00:05, 35.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6305884597185751, var=0.14917011915132738\n",
            "                Prec@(1) = 0.49246231155778897\n",
            "                Prec@(5) = 0.7989949748743719\n",
            "                Prec@(10) = 0.8844221105527639\n",
            "                Prec@(50) = 0.9597989949748744\n",
            "                NUMBER_OF_SAMPLES = 199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "305it [00:08, 36.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6660317054071487, var=0.15057589089474216\n",
            "                Prec@(1) = 0.5484949832775919\n",
            "                Prec@(5) = 0.8093645484949833\n",
            "                Prec@(10) = 0.882943143812709\n",
            "                Prec@(50) = 0.959866220735786\n",
            "                NUMBER_OF_SAMPLES = 299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "404it [00:11, 36.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6888550134357686, var=0.14874004731645663\n",
            "                Prec@(1) = 0.581453634085213\n",
            "                Prec@(5) = 0.8170426065162907\n",
            "                Prec@(10) = 0.8822055137844611\n",
            "                Prec@(50) = 0.9624060150375939\n",
            "                NUMBER_OF_SAMPLES = 399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "505it [00:14, 35.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6869953929611736, var=0.14633921675441897\n",
            "                Prec@(1) = 0.5731462925851704\n",
            "                Prec@(5) = 0.8236472945891784\n",
            "                Prec@(10) = 0.8877755511022044\n",
            "                Prec@(50) = 0.9639278557114228\n",
            "                NUMBER_OF_SAMPLES = 499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "608it [00:16, 37.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6695359670606238, var=0.15148676105345202\n",
            "                Prec@(1) = 0.5559265442404007\n",
            "                Prec@(5) = 0.8113522537562604\n",
            "                Prec@(10) = 0.8797996661101837\n",
            "                Prec@(50) = 0.9599332220367279\n",
            "                NUMBER_OF_SAMPLES = 599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "706it [00:19, 37.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6568992989706559, var=0.15171247991734502\n",
            "                Prec@(1) = 0.5364806866952789\n",
            "                Prec@(5) = 0.8054363376251789\n",
            "                Prec@(10) = 0.8798283261802575\n",
            "                Prec@(50) = 0.9613733905579399\n",
            "                NUMBER_OF_SAMPLES = 699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "807it [00:22, 39.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6565078593544529, var=0.15297307081108596\n",
            "                Prec@(1) = 0.5381727158948686\n",
            "                Prec@(5) = 0.7984981226533167\n",
            "                Prec@(10) = 0.8811013767209012\n",
            "                Prec@(50) = 0.9586983729662077\n",
            "                NUMBER_OF_SAMPLES = 799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "907it [00:24, 34.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.646050890533211, var=0.15603356899013857\n",
            "                Prec@(1) = 0.5283648498331479\n",
            "                Prec@(5) = 0.7842046718576196\n",
            "                Prec@(10) = 0.8743047830923248\n",
            "                Prec@(50) = 0.9566184649610678\n",
            "                NUMBER_OF_SAMPLES = 899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1005it [00:27, 36.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6232400263368402, var=0.16158002167605223\n",
            "                Prec@(1) = 0.5055055055055055\n",
            "                Prec@(5) = 0.7557557557557557\n",
            "                Prec@(10) = 0.8518518518518519\n",
            "                Prec@(50) = 0.954954954954955\n",
            "                NUMBER_OF_SAMPLES = 999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1107it [00:30, 41.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6093004690956824, var=0.16485697305261957\n",
            "                Prec@(1) = 0.4931756141947225\n",
            "                Prec@(5) = 0.7415832575068244\n",
            "                Prec@(10) = 0.83803457688808\n",
            "                Prec@(50) = 0.9554140127388535\n",
            "                NUMBER_OF_SAMPLES = 1099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1205it [00:32, 37.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.6003273118022452, var=0.16419727604711581\n",
            "                Prec@(1) = 0.48040033361134277\n",
            "                Prec@(5) = 0.7414512093411176\n",
            "                Prec@(10) = 0.8373644703919934\n",
            "                Prec@(50) = 0.9557964970809008\n",
            "                NUMBER_OF_SAMPLES = 1199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1306it [00:35, 36.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5837816014932127, var=0.16415488871321116\n",
            "                Prec@(1) = 0.4588144726712856\n",
            "                Prec@(5) = 0.7297921478060047\n",
            "                Prec@(10) = 0.827559661277906\n",
            "                Prec@(50) = 0.9576597382602001\n",
            "                NUMBER_OF_SAMPLES = 1299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1405it [00:38, 37.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5763766251007915, var=0.16408341410482244\n",
            "                Prec@(1) = 0.4496068620443174\n",
            "                Prec@(5) = 0.725518227305218\n",
            "                Prec@(10) = 0.8220157255182273\n",
            "                Prec@(50) = 0.9578270192994996\n",
            "                NUMBER_OF_SAMPLES = 1399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1504it [00:40, 36.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5680622571113388, var=0.16451334744513835\n",
            "                Prec@(1) = 0.4402935290193462\n",
            "                Prec@(5) = 0.7191460973982655\n",
            "                Prec@(10) = 0.8145430286857905\n",
            "                Prec@(50) = 0.9566377585056705\n",
            "                NUMBER_OF_SAMPLES = 1499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1605it [00:43, 37.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5594871634281547, var=0.16328964137279797\n",
            "                Prec@(1) = 0.4271419637273296\n",
            "                Prec@(5) = 0.7154471544715447\n",
            "                Prec@(10) = 0.8086303939962477\n",
            "                Prec@(50) = 0.9568480300187617\n",
            "                NUMBER_OF_SAMPLES = 1599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1706it [00:46, 38.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5575002005104885, var=0.16171984313874307\n",
            "                Prec@(1) = 0.4214243672748676\n",
            "                Prec@(5) = 0.7168922895821072\n",
            "                Prec@(10) = 0.8098881695114774\n",
            "                Prec@(50) = 0.9576221306650972\n",
            "                NUMBER_OF_SAMPLES = 1699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1804it [00:48, 38.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5502519653585857, var=0.1604037297048292\n",
            "                Prec@(1) = 0.4102279043913285\n",
            "                Prec@(5) = 0.7120622568093385\n",
            "                Prec@(10) = 0.8054474708171206\n",
            "                Prec@(50) = 0.9577543079488605\n",
            "                NUMBER_OF_SAMPLES = 1799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1904it [00:51, 37.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5430014097211325, var=0.15897313619927128\n",
            "                Prec@(1) = 0.39915745129015273\n",
            "                Prec@(5) = 0.7098472880463402\n",
            "                Prec@(10) = 0.8020010531858873\n",
            "                Prec@(50) = 0.9578725645076356\n",
            "                NUMBER_OF_SAMPLES = 1899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2005it [00:54, 38.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5328838002795744, var=0.15848384542357355\n",
            "                Prec@(1) = 0.3871935967983992\n",
            "                Prec@(5) = 0.7013506753376688\n",
            "                Prec@(10) = 0.7973986993496749\n",
            "                Prec@(50) = 0.9544772386193097\n",
            "                NUMBER_OF_SAMPLES = 1999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2105it [00:57, 36.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5259759229057125, var=0.15851972264042377\n",
            "                Prec@(1) = 0.3801810385898047\n",
            "                Prec@(5) = 0.6912815626488804\n",
            "                Prec@(10) = 0.7946641257741782\n",
            "                Prec@(50) = 0.9556931872320152\n",
            "                NUMBER_OF_SAMPLES = 2099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2206it [00:59, 36.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5165003361296584, var=0.15818904772883463\n",
            "                Prec@(1) = 0.37016825829922695\n",
            "                Prec@(5) = 0.6816734879490678\n",
            "                Prec@(10) = 0.7908140063665302\n",
            "                Prec@(50) = 0.9549795361527967\n",
            "                NUMBER_OF_SAMPLES = 2199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2307it [01:02, 36.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5165257635228279, var=0.15731512498698866\n",
            "                Prec@(1) = 0.3684210526315789\n",
            "                Prec@(5) = 0.6842105263157895\n",
            "                Prec@(10) = 0.7920835145715528\n",
            "                Prec@(50) = 0.9565028273162245\n",
            "                NUMBER_OF_SAMPLES = 2299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2408it [01:05, 39.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5192334343730025, var=0.15775247214694757\n",
            "                Prec@(1) = 0.37223843268028345\n",
            "                Prec@(5) = 0.688620258441017\n",
            "                Prec@(10) = 0.7932471863276365\n",
            "                Prec@(50) = 0.9558149228845352\n",
            "                NUMBER_OF_SAMPLES = 2399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2507it [01:07, 41.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.520196012421237, var=0.15889270526850338\n",
            "                Prec@(1) = 0.3753501400560224\n",
            "                Prec@(5) = 0.6866746698679472\n",
            "                Prec@(10) = 0.7915166066426571\n",
            "                Prec@(50) = 0.9531812725090036\n",
            "                NUMBER_OF_SAMPLES = 2499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2607it [01:10, 38.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.519861867598214, var=0.15968745733097417\n",
            "                Prec@(1) = 0.37629857637552905\n",
            "                Prec@(5) = 0.6852635629088111\n",
            "                Prec@(10) = 0.7876106194690266\n",
            "                Prec@(50) = 0.9507502885725279\n",
            "                NUMBER_OF_SAMPLES = 2599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2707it [01:13, 38.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5188632487840438, var=0.1601093078599576\n",
            "                Prec@(1) = 0.3760652093367914\n",
            "                Prec@(5) = 0.6835865135235273\n",
            "                Prec@(10) = 0.785846609855502\n",
            "                Prec@(50) = 0.9492404594294183\n",
            "                NUMBER_OF_SAMPLES = 2699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2805it [01:15, 37.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.516607207009532, var=0.1591844505983712\n",
            "                Prec@(1) = 0.37191854233654875\n",
            "                Prec@(5) = 0.68345837799214\n",
            "                Prec@(10) = 0.7852804573061808\n",
            "                Prec@(50) = 0.9496248660235799\n",
            "                NUMBER_OF_SAMPLES = 2799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2907it [01:18, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.520342110419513, var=0.1602568877302924\n",
            "                Prec@(1) = 0.3777164539496378\n",
            "                Prec@(5) = 0.6850638151086581\n",
            "                Prec@(10) = 0.7854432562952742\n",
            "                Prec@(50) = 0.9492928596067609\n",
            "                NUMBER_OF_SAMPLES = 2899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3004it [01:21, 36.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5238816006636915, var=0.16132254533253446\n",
            "                Prec@(1) = 0.38346115371790596\n",
            "                Prec@(5) = 0.6865621873957986\n",
            "                Prec@(10) = 0.7852617539179727\n",
            "                Prec@(50) = 0.9496498832944315\n",
            "                NUMBER_OF_SAMPLES = 2999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3105it [01:23, 39.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5276719838915536, var=0.16209757494672764\n",
            "                Prec@(1) = 0.3888351080993869\n",
            "                Prec@(5) = 0.6876411745724427\n",
            "                Prec@(10) = 0.7867053888351081\n",
            "                Prec@(50) = 0.9499838657631494\n",
            "                NUMBER_OF_SAMPLES = 3099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3207it [01:26, 36.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5304845317428625, var=0.16271612326263654\n",
            "                Prec@(1) = 0.3929352922788371\n",
            "                Prec@(5) = 0.6889653016567677\n",
            "                Prec@(10) = 0.7874335729915599\n",
            "                Prec@(50) = 0.9490465770553298\n",
            "                NUMBER_OF_SAMPLES = 3199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3308it [01:29, 38.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.533491196127205, var=0.16330960675862272\n",
            "                Prec@(1) = 0.397393149439224\n",
            "                Prec@(5) = 0.6905122764474083\n",
            "                Prec@(10) = 0.7884207335556229\n",
            "                Prec@(50) = 0.9490754774173992\n",
            "                NUMBER_OF_SAMPLES = 3299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3407it [01:31, 38.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5311174113099726, var=0.16364625977380837\n",
            "                Prec@(1) = 0.3957046190055899\n",
            "                Prec@(5) = 0.687849367461018\n",
            "                Prec@(10) = 0.7864077669902912\n",
            "                Prec@(50) = 0.9493968814357164\n",
            "                NUMBER_OF_SAMPLES = 3399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3504it [01:34, 41.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5331515354844186, var=0.16504909922995512\n",
            "                Prec@(1) = 0.4004001143183767\n",
            "                Prec@(5) = 0.6870534438410975\n",
            "                Prec@(10) = 0.7836524721348956\n",
            "                Prec@(50) = 0.9465561589025436\n",
            "                NUMBER_OF_SAMPLES = 3499\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3604it [01:37, 37.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5347663108813219, var=0.16521928082188173\n",
            "                Prec@(1) = 0.4026118366212837\n",
            "                Prec@(5) = 0.6888024451236454\n",
            "                Prec@(10) = 0.7843845512642401\n",
            "                Prec@(50) = 0.946651847735482\n",
            "                NUMBER_OF_SAMPLES = 3599\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3706it [01:39, 36.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5368119401949928, var=0.16595719157793987\n",
            "                Prec@(1) = 0.4060556907272236\n",
            "                Prec@(5) = 0.6891051635577183\n",
            "                Prec@(10) = 0.7837253311705866\n",
            "                Prec@(50) = 0.9451203027845364\n",
            "                NUMBER_OF_SAMPLES = 3699\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3806it [01:42, 34.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.540201930126992, var=0.16637020036643058\n",
            "                Prec@(1) = 0.41063437746775466\n",
            "                Prec@(5) = 0.6914977625690971\n",
            "                Prec@(10) = 0.785733087654646\n",
            "                Prec@(50) = 0.9452487496709661\n",
            "                NUMBER_OF_SAMPLES = 3799\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3906it [01:45, 37.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5463142750972066, var=0.16689247960277662\n",
            "                Prec@(1) = 0.41831238779174146\n",
            "                Prec@(5) = 0.6960759169017697\n",
            "                Prec@(10) = 0.7884072839189535\n",
            "                Prec@(50) = 0.9456270838676584\n",
            "                NUMBER_OF_SAMPLES = 3899\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4003it [01:47, 40.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5491130916390999, var=0.16641823992768634\n",
            "                Prec@(1) = 0.42060515128782194\n",
            "                Prec@(5) = 0.6999249812453113\n",
            "                Prec@(10) = 0.792198049512378\n",
            "                Prec@(50) = 0.946236559139785\n",
            "                NUMBER_OF_SAMPLES = 3999\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4106it [01:50, 38.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5513389178558423, var=0.16663286789085927\n",
            "                Prec@(1) = 0.42376189314466944\n",
            "                Prec@(5) = 0.7013905830690412\n",
            "                Prec@(10) = 0.7948280068309344\n",
            "                Prec@(50) = 0.9475481824835326\n",
            "                NUMBER_OF_SAMPLES = 4099\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4207it [01:53, 35.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.557728957505741, var=0.16687660297095783\n",
            "                Prec@(1) = 0.4315313169802334\n",
            "                Prec@(5) = 0.7063586568230531\n",
            "                Prec@(10) = 0.7980471540843058\n",
            "                Prec@(50) = 0.9483210288163848\n",
            "                NUMBER_OF_SAMPLES = 4199\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4307it [01:56, 36.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5596485849539362, var=0.16700643605410528\n",
            "                Prec@(1) = 0.43405443126308446\n",
            "                Prec@(5) = 0.7069085833914864\n",
            "                Prec@(10) = 0.7997208653175157\n",
            "                Prec@(50) = 0.9483600837404047\n",
            "                NUMBER_OF_SAMPLES = 4299\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4408it [01:58, 39.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                MRR: mean=0.5590392991583281, var=0.1670593908382492\n",
            "                Prec@(1) = 0.4335076153671289\n",
            "                Prec@(5) = 0.7062968856558308\n",
            "                Prec@(10) = 0.7999545351216185\n",
            "                Prec@(50) = 0.9479427142532394\n",
            "                NUMBER_OF_SAMPLES = 4399\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4496it [02:01, 37.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        MRR: mean=0.5606936559785274, var=0.16761464143469593\n",
            "        Prec@(1) = 0.43648498331479424\n",
            "        Prec@(5) = 0.7063403781979978\n",
            "        Prec@(10) = 0.7993325917686318\n",
            "        Prec@(50) = 0.9470522803114572\n",
            "        NUMBER_OF_SAMPLES = 4495\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "drfud_predictions = []\n",
        "print(test_loop(train_df, predict_FUDNet_DR_TEIT))\n",
        "\n",
        "with open(\"drfud_predictions_train.json\", 'w') as f:\n",
        "    json.dump(drfud_predictions, f)\n",
        "\n",
        "print(test_loop(test_df, predict_FUDNet_DR_TEIT))\n",
        "\n",
        "drfud_predictions = []\n",
        "with open(\"drfud_predictions_test.json\", 'w') as f:\n",
        "    json.dump(drfud_predictions, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv dr"
      ],
      "metadata": {
        "id": "IrehMxNzFRi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du . -ah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46lB20UrEK7M",
        "outputId": "0d889689-4076-40de-d047-2467e6ddacaf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388K\t./cache/IDFs.pkl\n",
            "38M\t./cache/tfidfVectorizer.pkl\n",
            "79M\t./cache/tfidf_wm.pkl\n",
            "1.5M\t./cache/title_to_embeddings.pkl\n",
            "388K\t./cache/words_to_IDF.pkl\n",
            "119M\t./cache\n",
            "106K\t./notebooks/DR_FUD.ipynb\n",
            "104K\t./notebooks/DR_SEKNN.ipynb\n",
            "240K\t./notebooks/DR_TEIT.ipynb\n",
            "273K\t./notebooks/IR_PLDA.ipynb\n",
            "0\t./notebooks/README.md\n",
            "2.0K\t./notebooks/utils_nlp.py\n",
            "891M\t./notebooks/train_unknown_df.json\n",
            "168M\t./notebooks/test_unknown_df.json\n",
            "253K\t./notebooks/DR_FUD_Unknown_labse.ipynb\n",
            "263K\t./notebooks/DR_FUD_Unknown_longformer.ipynb\n",
            "131K\t./notebooks/section_prediction.ipynb\n",
            "1.1G\t./notebooks\n",
            "9.5K\t./retrievers.py\n",
            "1.5M\t./doc_title_LaBSE_Embedding.npy\n",
            "1.5M\t./title_to_embeddings.pkl\n",
            "388K\t./IDFs.pkl\n",
            "31M\t./tfidfVectorizer.pkl\n",
            "79M\t./tfidf_wm.pkl\n",
            "9.0K\t./__pycache__/retrievers.cpython-37.pyc\n",
            "13K\t./__pycache__\n",
            "2.6G\t./secpred_dataset.pkl\n",
            "19M\t./drfud_predictions_train.json\n",
            "512\t./drfud_predictions_test.json\n",
            "3.9G\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_loop(train_df, predict_KNN_FUDNet_DR_TEIT))"
      ],
      "metadata": {
        "id": "SdGwYLfIxV3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH9vqWah_hFc"
      },
      "source": [
        "# Results\n",
        "\n",
        "At last we have resutls as follows:\n",
        "\n",
        "\n",
        "| Method | @1 | @5 | @10 | @50 | @100 | MRR (mean, var) |\n",
        "|:------:|:------:|:------:|:-------:|:-------:|:--------:|:---:|\n",
        "| IDF - vanilla | 13% | 30% | 39% | 64% | 83% | (0.22, 0.11) |\n",
        "| IDF - power-order | 15% | 31% | 41% | 65% | 83% | (0.23, 0.12) |\n",
        "| IDF - power-order (softmax) | 10.7% | 23% | 31% | 57.6% | 78% | (0.18, 0.09) |\n",
        "| IDF - self-attention | 13.9% | 29% | 38% | 62% | 82% | (0.22, 0.11) |\n",
        "| DR. TEIT | 61.6% | 86% | 91% | 96% | 98% | (0.72, 0.13) |\n",
        "| DR. TEIT (val) | 40.0% | 69.25% | 92.4% | 99% | 98% | (0.53, 0.16) |\n",
        "| FUDNet + DR. TEIT | 67% | 87% | 91% | 96% | 99% | (0.76, 0.12) |\n",
        "| FUDNet + DR. TEIT (val) | 48.2% | 75.48% | 82% | 93% | 99% | (0.60, 0.16) |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MRR: mean=0.7605851824924286, var=0.12850709866222307\n",
        "                Prec@(1) = 0.6706096451319381\n",
        "                Prec@(5) = 0.8698817106460418\n",
        "                Prec@(10) = 0.910828025477707\n",
        "                Prec@(50) = 0.9681528662420382\n",
        "                NUMBER_OF_SAMPLES = 1099"
      ],
      "metadata": {
        "id": "SczaywmN6Y0m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ3M9TEuFq_M"
      },
      "source": [
        "# drafts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_fudnet_test():\n",
        "  data = {\"combined\": \" <SEP> Hello. how can you help me?\", \"label\": 0}\n",
        "  inputs = tokenize_function(data, prediction=True, cuda=True)\n",
        "  labels = torch.tensor([data['label']]).unsqueeze(0)  # Batch size 1\n",
        "  outputs = fudnet_model(**inputs)\n",
        "  prediction = torch.argmax(outputs.logits)\n",
        "  print(prediction)\n",
        "\n",
        "simple_test()"
      ],
      "metadata": {
        "id": "VxPrLsnz-ccc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbPuutLoOvsK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, T5Tokenizer, T5EncoderModel\n",
        "import torch\n",
        "\n",
        "model_name = [\"setu4993/LaBSE\", \"t5-small\", \"bert-base-uncased\"][0]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "# model = T5EncoderModel.from_pretrained(\"t5-base\")\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(\"inputs\", inputs)\n",
        "\n",
        "print(\"last_hidden_states\", last_hidden_states.shape)\n",
        "\n",
        "# pooler = outputs.pooler_output\n",
        "# print(\"pooler\",pooler.shape)\n",
        "# with torch.no_grad():\n",
        "#     print(np.squeeze(np.array(pooler)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlFbxcxK3Ljs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from utils import scaled_dot_product_attention\n",
        "\n",
        "inputs = tokenizer([\"Hello, my dog is cute\", \"Yes this is a beautiful dog and you can have it.\"], max_length=16, padding=\"max_length\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "query=last_hidden_states[0, :, :]\n",
        "key=last_hidden_states[1, :, :]\n",
        "value=last_hidden_states[1, :, :]\n",
        "\n",
        "context, attention = scaled_dot_product_attention(\n",
        "    query=query,\n",
        "    key=key,\n",
        "    value=value,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQVqMhWX3Ljt",
        "outputId": "82a25d9c-062b-4718-d282-cb16d839aa3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([16, 768]), torch.Size([16, 16]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context.shape , attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGySpDFl3Lju",
        "outputId": "9a72f319-e934-4272-962c-6b5defd4c85b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "with torch.no_grad():\n",
        "    plt.imshow(attention, interpolation='nearest')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0RaKNZY3Ljv",
        "outputId": "40a57ea1-25e6-4c09-933f-03aff38a8942"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4.1652e-05, 1.8743e-08, 4.3531e-15, 1.3554e-17, 2.0464e-16, 1.3552e-08,\n",
              "         9.9992e-01, 1.8685e-20, 2.9881e-23, 3.2375e-22, 4.0948e-22, 5.8909e-23,\n",
              "         5.1022e-18, 4.1652e-05, 1.0425e-15, 3.1295e-16],\n",
              "        [6.9659e-16, 5.0016e-07, 1.9475e-12, 6.0816e-15, 4.3889e-14, 1.0717e-07,\n",
              "         1.0000e+00, 1.2967e-17, 1.6856e-19, 1.3311e-18, 2.6679e-18, 2.0186e-19,\n",
              "         6.4972e-16, 6.9659e-16, 3.3120e-14, 1.4395e-14],\n",
              "        [2.8160e-17, 4.6376e-12, 3.3828e-09, 3.1156e-10, 7.6270e-09, 3.4791e-07,\n",
              "         1.0000e+00, 1.6709e-13, 7.2155e-15, 7.7347e-15, 2.2479e-14, 1.4072e-14,\n",
              "         3.9355e-12, 2.8160e-17, 7.8200e-14, 8.5553e-14],\n",
              "        [8.9966e-22, 3.2495e-17, 1.8656e-13, 6.4120e-14, 1.5420e-11, 2.0936e-09,\n",
              "         1.0000e+00, 3.8246e-18, 1.3870e-19, 3.8302e-19, 3.0957e-18, 2.5225e-19,\n",
              "         1.7452e-17, 8.9966e-22, 3.4182e-18, 3.9053e-18],\n",
              "        [1.0318e-33, 1.2762e-28, 2.2427e-30, 7.8236e-32, 1.9107e-27, 3.6965e-22,\n",
              "         1.0000e+00, 3.1281e-36, 1.3927e-38, 2.2895e-37, 1.5183e-36, 5.2110e-38,\n",
              "         4.2408e-35, 1.0318e-33, 5.6916e-34, 2.6557e-34],\n",
              "        [2.9877e-19, 1.8721e-15, 7.1188e-10, 7.5957e-10, 9.5682e-08, 1.9970e-06,\n",
              "         1.0000e+00, 8.9723e-14, 7.0886e-15, 7.2686e-15, 2.1089e-14, 9.9914e-15,\n",
              "         2.6498e-13, 2.9877e-19, 2.0165e-15, 2.6876e-15],\n",
              "        [7.4719e-22, 5.1469e-17, 6.6067e-16, 1.9406e-16, 2.8237e-13, 1.2238e-05,\n",
              "         9.9999e-01, 2.6902e-20, 6.5572e-22, 3.2489e-21, 8.4031e-21, 5.6765e-22,\n",
              "         3.0449e-20, 7.4719e-22, 4.7050e-20, 4.0429e-20],\n",
              "        [4.1652e-05, 1.8743e-08, 4.3531e-15, 1.3554e-17, 2.0464e-16, 1.3552e-08,\n",
              "         9.9992e-01, 1.8685e-20, 2.9880e-23, 3.2375e-22, 4.0949e-22, 5.8910e-23,\n",
              "         5.1022e-18, 4.1652e-05, 1.0425e-15, 3.1296e-16],\n",
              "        [5.9133e-15, 9.5168e-11, 2.9626e-09, 5.4552e-11, 8.0166e-10, 4.4084e-07,\n",
              "         1.0000e+00, 1.6482e-12, 5.3448e-14, 5.9957e-14, 2.1881e-13, 1.3077e-13,\n",
              "         1.2206e-11, 5.9133e-15, 5.7231e-07, 3.3679e-07],\n",
              "        [9.3829e-15, 1.1562e-10, 2.0312e-09, 3.8886e-11, 5.3428e-10, 3.4737e-07,\n",
              "         1.0000e+00, 1.2102e-12, 3.6069e-14, 4.4100e-14, 1.6976e-13, 9.6020e-14,\n",
              "         9.4887e-12, 9.3829e-15, 8.3791e-07, 5.1095e-07],\n",
              "        [5.2414e-15, 8.6201e-11, 1.4455e-09, 2.4929e-11, 3.8093e-10, 3.0065e-07,\n",
              "         1.0000e+00, 8.3030e-13, 2.2826e-14, 2.7789e-14, 1.2366e-13, 6.0846e-14,\n",
              "         5.6131e-12, 5.2414e-15, 1.0698e-06, 5.7978e-07],\n",
              "        [3.0958e-15, 4.6744e-11, 1.6457e-09, 2.8861e-11, 4.2559e-10, 2.4767e-07,\n",
              "         1.0000e+00, 8.3148e-13, 2.3863e-14, 2.9668e-14, 1.1722e-13, 6.3246e-14,\n",
              "         5.7814e-12, 3.0958e-15, 9.5961e-07, 4.9884e-07],\n",
              "        [1.8006e-14, 1.9729e-10, 1.4437e-09, 2.0318e-11, 2.4315e-10, 2.3768e-07,\n",
              "         1.0000e+00, 7.8998e-13, 1.9282e-14, 2.3731e-14, 1.0645e-13, 5.7221e-14,\n",
              "         6.2588e-12, 1.8006e-14, 2.6341e-06, 1.4341e-06],\n",
              "        [8.4964e-15, 1.3390e-10, 1.1086e-09, 1.4253e-11, 1.9078e-10, 2.0294e-07,\n",
              "         1.0000e+00, 6.0238e-13, 1.3977e-14, 1.6624e-14, 7.8173e-14, 3.9471e-14,\n",
              "         4.1144e-12, 8.4965e-15, 2.1830e-06, 1.1469e-06],\n",
              "        [2.4448e-14, 2.9755e-10, 1.9748e-09, 2.3722e-11, 2.6664e-10, 2.9164e-07,\n",
              "         9.9999e-01, 1.1013e-12, 2.8862e-14, 3.5822e-14, 1.4386e-13, 8.3851e-14,\n",
              "         9.6447e-12, 2.4448e-14, 4.6905e-06, 2.2014e-06],\n",
              "        [1.8272e-14, 2.1756e-10, 1.5898e-09, 2.3002e-11, 2.6720e-10, 2.2422e-07,\n",
              "         1.0000e+00, 9.2031e-13, 2.4502e-14, 3.0381e-14, 1.2275e-13, 7.0096e-14,\n",
              "         7.7049e-12, 1.8272e-14, 2.8986e-06, 1.6224e-06]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9upZg7Ge3Ljw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "R6Ju0mlj09Mm",
        "nyjeHgyD1xRJ"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d6870f987f6424eb0810ef9f1cac3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e91f634b4ac64907b6cbc0278df8dd69",
              "IPY_MODEL_95d4713c357e4986abd6b5cbf51752c7",
              "IPY_MODEL_c711a512e578435f9e1bb5dd83cb1b8d"
            ],
            "layout": "IPY_MODEL_7346eab318024c9287da2c543c42cb0a"
          }
        },
        "e91f634b4ac64907b6cbc0278df8dd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1450ff44f4274dbc839fb1d23b7221bf",
            "placeholder": "​",
            "style": "IPY_MODEL_0d18bacc7f484c41ac55a0c172646493",
            "value": "100%"
          }
        },
        "95d4713c357e4986abd6b5cbf51752c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6f506d27db4ae1adca5fed43ee2719",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d98e1f84a4224ac2b490c92f3d194fea",
            "value": 24
          }
        },
        "c711a512e578435f9e1bb5dd83cb1b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d524d60fe649a7ba6a3ddb8169a970",
            "placeholder": "​",
            "style": "IPY_MODEL_da6eb447a73648b6a8945aaa4b239cb5",
            "value": " 24/24 [00:03&lt;00:00,  7.51ba/s]"
          }
        },
        "7346eab318024c9287da2c543c42cb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1450ff44f4274dbc839fb1d23b7221bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d18bacc7f484c41ac55a0c172646493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6f506d27db4ae1adca5fed43ee2719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98e1f84a4224ac2b490c92f3d194fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2d524d60fe649a7ba6a3ddb8169a970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6eb447a73648b6a8945aaa4b239cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc24443458a54495b33a0c7f7763bb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6b365157aa94949a53b600ab41d4f2b",
              "IPY_MODEL_c100142a51c8492d8c82bc0ba277420d",
              "IPY_MODEL_6482b54cfe274659b5bc6f896fd51675"
            ],
            "layout": "IPY_MODEL_a1789b6c64d24221a8fd74e2d1425cd8"
          }
        },
        "d6b365157aa94949a53b600ab41d4f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2fe805e2ec40b59a73b15187c96c94",
            "placeholder": "​",
            "style": "IPY_MODEL_17ff5a6cf7f24391bc3f1e275cc307c3",
            "value": "100%"
          }
        },
        "c100142a51c8492d8c82bc0ba277420d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c622fa2d154766ab283dba7a6366d7",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afda3c88f3334d7895aa642167c45beb",
            "value": 5
          }
        },
        "6482b54cfe274659b5bc6f896fd51675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2ec52410a94156ae7d850a9e0f69a3",
            "placeholder": "​",
            "style": "IPY_MODEL_8932c110b4ec412f957bd01516ba1b5a",
            "value": " 5/5 [00:00&lt;00:00,  7.11ba/s]"
          }
        },
        "a1789b6c64d24221a8fd74e2d1425cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2fe805e2ec40b59a73b15187c96c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ff5a6cf7f24391bc3f1e275cc307c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41c622fa2d154766ab283dba7a6366d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afda3c88f3334d7895aa642167c45beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d2ec52410a94156ae7d850a9e0f69a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8932c110b4ec412f957bd01516ba1b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3347e9ff5058477c95f3d885a90d1c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b6f0cf917ec49cd9e1a79f095a32c79",
              "IPY_MODEL_0bf60789e6bf4003b75dff517dd265b3",
              "IPY_MODEL_592629bce15f4518801cf80f1d06f813"
            ],
            "layout": "IPY_MODEL_8e3f8511dbb34eef8383b3d6a8a5e518"
          }
        },
        "7b6f0cf917ec49cd9e1a79f095a32c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e96fd6eaba94c6abb8a3430be5dcdeb",
            "placeholder": "​",
            "style": "IPY_MODEL_5ed0c6780af44696b1aee67f1886bc05",
            "value": "Downloading builder script: "
          }
        },
        "0bf60789e6bf4003b75dff517dd265b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac0a5e3bf70410e84d7962d6bff575f",
            "max": 1411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f82fdad7e54148909c3ff564f4adab86",
            "value": 1411
          }
        },
        "592629bce15f4518801cf80f1d06f813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecf6d418527465f82f2099bca0e020a",
            "placeholder": "​",
            "style": "IPY_MODEL_349af9aa536a4386b99f3278a0503e2a",
            "value": " 3.19k/? [00:00&lt;00:00, 103kB/s]"
          }
        },
        "8e3f8511dbb34eef8383b3d6a8a5e518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e96fd6eaba94c6abb8a3430be5dcdeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed0c6780af44696b1aee67f1886bc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac0a5e3bf70410e84d7962d6bff575f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82fdad7e54148909c3ff564f4adab86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eecf6d418527465f82f2099bca0e020a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349af9aa536a4386b99f3278a0503e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}